---
title: 'Studie: Flow beim Laufen'
author: "Simon Bogutzky"
date: "April 2015"
output:
  pdf_document:
    fig_caption: yes
    fig_crop: no
    highlight: null
    keep_tex: yes
header-includes: \usepackage[ngerman]{babel} \usepackage[printonlyused,withpage]{acronym}
  \usepackage{setspace} \usepackage{natbib} \usepackage{booktabs} \onehalfspacing
fontsize: 11pt
documentclass: scrartcl
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
  
  # Remove all variables
  rm(list = ls(all = T)) 

  # Set working directory
  setwd("~/Entwicklung/bogutzky/repositories/non-disruptive-flow-measures")

  # Load libraries
  library("flow")
  library("xtable")
  
  fss.features <- read.csv("./data/features/fss-features.csv", stringsAsFactors = FALSE)
  hrv.features <- read.csv("./data/features/hrv-features.csv", stringsAsFactors = FALSE)
  
  # Set start time
  start.time <- as.POSIXct("2013-10-31", tz="CET")
```

# Abkürzungsverzeichnis

\begin{acronym}[TDMA]
  \acro{AFP}{Anforderungs-Fähigkeits-Passung}
  \acro{ANS}{autonome Nervensystem}
	\acro{EKG}{Elektrokardiogramm}
	\acro{ESM}{Experience Sampling Method}
  \acro{FFT}{Fast Fourier Transformation}
	\acro{FKS}{Flow-Kurzskala}
	\acro{GPS}{Global Positioning System}
  \acro{HF}{High Frequency}
	\acro{HRV}{Herzratenvariabilität}
  \acro{LF}{Low Frequency}
  \acro{VHF}{Very High Frequency}
  \acro{WT}{Wavelet Transformation}
\end{acronym}

# Ziel
Die Studie diente dazu statistische Beziehungen zwischen:

* Flow und der Aktivität des autonomen Nervensystems
* Flow und dem Bewegungsfluss

beim Laufen herzustellen. Des Weiteren suchte ich in den Daten nach markanten Mustern, die den Eintritt in den Flow, Flow selbst und den Austritt aus dem Flow markieren.

# Methode
## Flow-Diagnostik
### Flow-Kurzskala

Zur subjektiven Erfassung des Flow-Erlebens kam die \ac{FKS} von \citet{Rheinberg2003} zum Einsatz. Die \ac{FKS} besteht aus insgesamt 16 Items. Die ersten zehn Items bilden anhand einer 7-Punkte-Likert-Skala ("trifft nicht zu" = 1 bis "trifft zu" = 7) Komponenten des Flow-Erlebens ab und \citet{Rheinberg2003} fassen sie als Generalfaktor zusammen. Zur Differenzierung des Flow-Konstrukts ist der Generalfaktor der \ac{FKS} in zwei Faktoren (Subdimensionen) unterteilt. Faktor I umfasst sechs Items, die Aussagen zum "Glatten automatisierten Verlauf" einer Tätigkeit beschreiben. Faktor II beinhaltet vier Items, die mit "Absorbiertheit" in Zusammenhang stehen. Der Reliabilitätskoeffizient der zehn Items im Generalfaktor (Cronbachs Alpha) liegt nach Angaben von \citet[S. 9]{Rheinberg2003} im Bereich um $\alpha = 0.90$. Da nicht damit zu rechnen ist, dass in Anforderungssituationen ausschließlich Flow entsteht, sondern Anforderungssituationen auch Angst und Besorgnis auslösen können, erweiterten \citet{Rheinberg2003} die \ac{FKS} durch eine "Besorgniskomponente". Diese besteht aus drei Items (Nr. 11 bis 13, Cronbachs $\alpha = 0.80$ bis $\alpha = 0.90$). Am Ende der \ac{FKS} nehmen die Probanden drei Einschätzungen zur \ac{AFP} (auf einer 9-Punkte-Skala) vor. Das Item 14 fokussiert sich auf einen Vergleich der Schwierigkeit der jetzigen Tätigkeit mit allen anderen Tätigkeiten (leicht vs. schwer) und das Item 15 auf die eigene Leistungsfähigkeit (niedrig vs. hoch). Das Item 16 fragt direkt, auf die aktuelle Tätigkeit bezogen, nach der subjektiv wahrgenommenen \ac{AFP} (zu gering vs. zu hoch). 

## Untersuchungsdesign 
Ein männlicher Freizeitläufer (29) nahm am Experiment teil. Er lief in sechs aufeinanderfolgenden Wochen an einem Tag 60 Minuten jeweils die gleiche Strecke und zur gleichen Tageszeit.

Vor jedem Lauf rüstete ich ihn mit einem geladenen Smartphone, einem passenden Smartphone-Armband, zwei geladenen Bewegungssensoren, einem geladenen \ac{EKG}-Sensoren und vier Elektroden aus. Die Anordnung des Equipments ist Abbildung \ref{fig:anordnung-des-equipments} zu entnehmen.

\begin{figure}[htbp]
\centering
\includegraphics[keepaspectratio,width=0.75\textwidth]{./figures/equipment-arrangement.pdf}
\caption{Anordnung des Equipments}
\label{fig:anordnung-des-equipments}
\end{figure}

Während jedes Laufes zeichnete eine eigens entwickelte App \ac{EKG} und Bewegungsdaten mit Hilfe der tragbaren Sensoren des Unternehmens Shimmer Research (Shimmer 2r) auf. Die App läuft auf dem Android OS ab Version 4.4 und kommuniziert mit den Sensoren über Bluetooth. Die Bewegungssensoren besitzen einen Beschleunigungsmesser und ein Kreiselinstrument, die beide auf jeweils drei Achsen messen. Für das Experiment nutzte ich das Smartphone Samsung Galaxy Nexus, welches auch über einen Beschleunigungsmesser und ein Kreiselinstrument verfügt. Alle Bewegungssensoren arbeiten mit einer Datenrate von 100 Hz. Der \ac{EKG}-Sensor von Shimmer Research arbeitet mit vier Ableitungen. Im Experiment nutzte ich Knopfelektroden und eine Datenrate von 256 Hz. Alle 15 Minuten während jedes Laufes forderte die App mit einem Signal den Läufer auf, eine \ac{FKS} auszufüllen. Vor jedem Lauf führte der Läufer eine 15-minütige Baseline Messung durch. 

Nach jedem Lauf übertrug ich die gesammelten Daten für die software-technische Analyse auf meinen Arbeitsrechner. Die Daten bestehen für jeden Lauf aus der Bewertung der fünf \ac{FKS}, \ac{EKG}-Daten, \ac{GPS}-Positionen, Beschleunigungen und Winkelgeschwindigkeiten von den Körperpositionen Bein, Arm und Handgelenk. 

### Datenverarbeitung
#### Flow-Kurzskala
Aus der Bewertung der \ac{FKS} berechnete ich die Faktoren der \ac{FKS}. Tabelle \ref{tab:fks-merkmale} zeigt die Ergebnisse der \ac{FKS} des Laufes vom Donnerstag, den 31. Oktober 2013. In dieser Sitzung steigt z. B. die \ac{AFP} kontinuierlich und beim Laufen bewertet der Läufer seine Absorbiertheit gleichbleibend im mittleren Bereich (siehe Abbildung \ref{fig:absorbiertheit-afp-verlauf}). 

```{r fks-merkmale, echo=FALSE, message=FALSE, results="asis"}
    
  # Subset features
    fss.features.subset         <- fss.features[start.time + 60 * 60 * 24 > as.POSIXct(fss.features[,12], tz="CET") & as.POSIXct(fss.features[,12], tz="CET") > start.time, c(1:10, 12:15)]
    
  # Create table structure
  fss.features.table          <- fss.features.subset[,1:10]
  fss.features.table.factors  <- fss.features.table[,c(1,3,5,7,9)]
  fss.features.table.sds      <- fss.features.table[,c(2,4,6,8,10)]
  fss.features.table          <- data.frame()
  for (i in 1:nrow(fss.features.subset)) {
    fss.features.table          <- rbind(fss.features.table, as.numeric(fss.features.table.factors[i,]))
    fss.features.table          <- rbind(fss.features.table, as.numeric(fss.features.table.sds[i,]))
  }

  # Clean up
  fss.features.table          <- t(fss.features.table)
  rm(fss.features.table.factors, fss.features.table.sds)
  
  # Name data
  colnames(fss.features.table)  <- rep(c("M", "SD"), i)
  rownames(fss.features.table)  <- c("Generalfaktor", "glatter Verlauf", "Absorbiertheit", "Besorgnis", "AFP")
  
  # Create latex table
  table           <- xtable(fss.features.table, caption = paste("Ergebnisse vom", strftime(start.time, format = "%A, den %d. %B %Y")), label = "tab:fks-merkmale")

  # Add second header
  addtorow          <- list()
  addtorow$pos      <- list()
  addtorow$pos[[1]] <- 0
  addtorow$command <- c("& \\multicolumn{2}{c}{Baseline} & \\multicolumn{2}{c}{Nach 15 Min.} & \\multicolumn{2}{c}{Nach 30 Min.} & \\multicolumn{2}{c}{Nach 45 Min.} & \\multicolumn{2}{c}{Nach 60 Min.} \\\\\n")
  print(table, caption.placement = "top", sanitize.rownames.function = function(x){x}, comment = FALSE, add.to.row = addtorow, include.colnames = FALSE)
  
  # Clean up
  rm(fss.features.table, table, addtorow)
```

Zur Bewertung des subjektiven Flow-Zustands verwende ich die zweite Subdimension der \ac{FKS}. Denn die Absorbiertheit tritt laut \citet{Peifer2014} nur ein, wenn Anforderungen und Fähigkeiten sich in Balance befinden — somit ist sie ausschließlich im *Flow-Kanal* anzutreffen. Deshalb die Absorbiertheit ein repräsentativer Indikator für Flow als der Generalfaktor, der sich aus den zwei Subdimension zusammensetzt. Den Beleg hierfür geben \citet[S. 69]{Rheinberg2003a}. Sie stellten fest, dass Unterforderung keinen Einfluss auf den glatten Verlauf hat, jedoch die Absorbiertheit negativ beeinflusst. Auch im Vergleich von Baseline und Laufmessung (siehe Abbildung \ref{fig:absorbiertheit-afp-verlauf}) ist dieser Sachverhalt auszumachen. 

<!-- Hier kommt noch was zum FKS-Gesamtergebnis hin oder etwas später -->

```{r absorbiertheit-afp-verlauf, echo=FALSE, warning=FALSE, dev='pdf', fig.height=3, fig.width=6.5, fig.pos='htbp', fig.cap='Absorbiertheit, AFP und glatter Verlauf'}
  par(mfcol=c(1, 1), mar=c(3.5, 3.5, 1.5, 3.5) + 0.1, mgp=c(2, .5, 0), las=1, cex.axis=0.8, tck=.01, cex.lab=.8)
  
  # Plot data
  plot(as.POSIXct(fss.features.subset[,11]), fss.features.subset[,5], type="b", xlab ="Zeitpunkt", ylab="", pch=21, xlim = c(min(as.POSIXct(fss.features.subset[,11]))-60, max(as.POSIXct(fss.features.subset[,11]))+60), ylim=c(3, 6), xaxt="n", yaxt="n")
  lines(as.POSIXct(fss.features.subset[,11]), fss.features.subset[,9], type = "b", pch=22)
  lines(as.POSIXct(fss.features.subset[,11]), fss.features.subset[,3], type = "b", pch=23)

  # Plot ticks
  axis(1, at=as.POSIXct(fss.features.subset[,11]), label=format(as.POSIXct(fss.features.subset[,11]),"%H:%M:%S"))
  axis(2, at=seq(3, 6, .5), labels=seq(3, 6, .5))
  axis(3, at=as.POSIXct(fss.features.subset[,11]), label=rep("", length(fss.features.subset[,11])))
  axis(4, at=seq(3, 6, .5), labels=rep("", length(seq(3, 6, .5))))

  legend("bottomright", inset=.05, c("Absorbiertheit", "AFP", "Glatter Verlauf"), pch = c(21:22), cex = .7)

  # Plot box again
  box()
```

#### HRV-Analyse
Von den \ac{EKG}-Daten entfernte ich die Zeiten für die Bewertung der \ac{FKS} und erhielt jeweils 15-Minuten Abschnitte (siehe Abbildung \ref{fig:ekg-signalverarbeitung} von A zu B). Zur effizienteren Verarbeitung in KubiosHRV teilte ich die 15-Minuten Abschnitte in jeweils drei fünf Minuten Abschnitte (siehe Abbildung \ref{fig:ekg-signalverarbeitung} C). Zur RR-Interval Berechnung las ich die 90 fünf Minuten Abschnitte in KubiosHRV (Version 2.1) ein. KubiosHRV R-Spitzen-Erkennung identifiziert grötenteils die Herzschläge automatisch, trotzdem ist eine manuelle Nachbearbeitung notwendig. Nicht erkannte Herzschläge fügte ich hinzu und zuviel erkannte Herzschläge entfernte ich. \ac{EKG}-Daten mit mehr als 2% an Artefakten habe ich aus der Datensammlung entfernt. 
Zur \ac{HRV}-Analyse nutze ich die letzten fünf Minuten jedes 15-Minuten Abschnittes. Das hatte folgende Gründe:

- Die ersten fünf Minuten sind beeinflusst von der Ruhephase vor dem Lauf und nach jeder Befragung (siehe Abbildung \ref{fig:ekg-signalverarbeitung} C am Anfang)
- Die letzten fünf Minuten liegen direkt vor der Befragung (siehe Abbildung \ref{fig:ekg-signalverarbeitung} C am Ende)
- Für die letzten fünf Minuten musste ich keinen Datensatz aufgrund von Artefakten aus der Datensammlung entfernen

```{r ekg-signalverarbeitung, echo=FALSE, warning=FALSE, dev='CairoPNG', dpi=800, fig.height=4.5, fig.width=6.5, fig.pos='htbp', fig.cap='EKG-Signalverarbeitung'}
  par(mfcol=c(4, 1), mar=c(3, 3, 1.5, 3) + 0.1, mgp=c(2, .5, 0), las=1, cex.axis=0.8, tck=.01, cex.lab=.8, xaxs="i", yaxs="i")

  # Load ecg data  
  ecg.data.file.path <- paste("./data/cleaned-data/running/buse-patrick/", strftime(as.POSIXct(fss.features.subset[2,11], tz="CET"), "%Y-%m-%d--%H-%M-%S"), "/", sep="")
  ecg.data  <- read.csv(paste(ecg.data.file.path, "/ecg-data.csv", sep=""), header=T)

    # Load Kubios HRV txt data
  kubios.hrv.data.path  <- paste("./data/example-data/running/buse-patrick/", strftime(as.POSIXct(fss.features.subset[2,11], tz="CET"), "%Y-%m-%d--%H-%M-%S"), "/", sep="")
  kubios.hrv.data       <- read.csv(paste(kubios.hrv.data.path, "/ecg-data-4_hrv.txt", sep = ""), header = F, na.strings = "", fill = T, skip = 117, stringsAsFactors = FALSE, col.names = c("", "Time", "RR.interval", "FFT.Frequency", "FFT.PSD", "AR.Frequency", "AR.PSD", "VLF.comp.", "LF.comp.", "HF.comp.", ""))[,2:10]
  
  # Get time and rr-intervals
  time              <- kubios.hrv.data[, 1]
  time              <- time[complete.cases(time)]
  rr.interval       <- kubios.hrv.data[, 2]
  rr.interval       <- rr.interval[complete.cases(rr.interval)]
  
  # Set time properties
  starts    <- as.POSIXct(fss.features.subset[,11], tz="CET")
  ends      <- as.POSIXct(fss.features.subset[,12], tz="CET")
  times     <- as.POSIXct(ecg.data[, 4]/1000, origin="1970-01-01", tz="CET")
  
  # Set data
  t     <- ecg.data[, 1]
  y     <- ecg.data[, 3]
  end   <- ends[length(ends)]
  start <- starts[length(starts)]
  
  # Plot all ecg data
  plot(t, y, type="l", xlab="", ylab=expression("EKG LA LL ["~mV~"]"), xaxt="n", yaxt="n", col=1)
  par(new = T)
  plot(times, y, type="n", xlab="", ylab="", xaxt="n", yaxt="n")

  # Mark interesting part
  polygon(c(start, start, end, end), c(-10, 10, 10, -10), col = rgb(1, 1, 1, .2), border = rgb(0, 0, 0, 0))
  
  # Plot ticks and vertical lines
  axis(1, at=c(starts, ends), label=format(c(starts, ends), "%H:%M:%S"))
  axis(2, at=seq(-6, 6, 2), labels=seq(-6, 6, 2))
  axis(3, at=c(starts, ends), label=rep("", length(c(starts, ends))))
  axis(4, at=seq(-6, 6, 2), labels=rep("", length(seq(-6, 6, 2))))
  abline(v=starts, lty="dashed", col="grey")
  abline(v=ends, lty="dashed", col="grey")
  
  # Plot box again
  box()
  
  # Add reference letter  
  mtext("A", 4, line=2)

  # Plot the last 15 minutes of ecg data
  isIn         <- start - 30 <= times & end + 30 >= times
  t            <- t[isIn]
  y            <- y[isIn]
  times.subset <- times[isIn]
  
  plot(t, y, type="l", xlab="", ylab=expression("EKG LA LL ["~mV~"]"), xaxt="n", yaxt="n", col=1)
  par(new = T)
  plot(times.subset, y, type="n", xlab="", ylab="", xaxt="n", yaxt="n")

  # Plot ticks and vertical lines
  axis(1, at=c(starts, ends), label=format(c(starts, ends), "%H:%M:%S"))
  axis(2, at=seq(-6, 6, 2), labels=seq(-6, 6, 2))
  axis(3, at=c(starts, ends), label=rep("", length(c(starts, ends))))
  axis(4, at=seq(-6, 6, 2), labels=rep("", length(seq(-6, 6, 2))))
  abline(v=starts, lty="dashed", col="grey")
  abline(v=ends, lty="dashed", col="grey")

  # Plot box again
  box()

  # Add reference letter  
  mtext("B", 4, line=2)

  # Set data
  t         <- time
  y         <- rr.interval
  end.rr    <- max(t)
  start.rr  <- min(t)
  xlim      <- c(start.rr - 30, end.rr + 30)
  
  # Plot rrIntervals
  plot(t, y, type="l", xlab="", ylab=expression("RR-Intervalle ["~s~"]"), xaxt="n", yaxt="n", xlim=xlim, col=1)

  # Mark interesting part
  polygon(c(end.rr - 5 * 60, end.rr - 5 * 60, end.rr, end.rr), c(0, 1, 1, -0), col = rgb(1, 1, 1, .2), border = rgb(0, 0, 0, 0))

  # Plot ticks and vertical lines
  marker <- c(start.rr, end.rr - 10 * 60, end.rr - 5 * 60, end.rr)
  axis(1, at=marker, label=format(c(start, end - 10 * 60, end - 5 * 60, end), "%H:%M:%S"))
  axis(2, at=seq(.25, .50, .05), labels=seq(.25, .50, .05))
  axis(3, at=marker, label=rep("", length(marker)))
  axis(4, at=seq(.25, .50, .05), labels=rep("", length(seq(.25, .50, .05))))
  abline(v=marker, lty = "dashed", col="darkgrey")

  # Plot box again
  box()

  # Add reference letter  
  mtext("C", 4, line=2)

  # Set data
  t         <- time[time > max(time) - 5 * 60]
  y         <- rr.interval[time > max(time) - 5 * 60]
  end.rr    <- max(t)
  start.rr  <- min(t)
  xlim      <- c(start.rr - 10, end.rr + 10)
  
  # Plot rrIntervals
  plot(t, y, type="l", xlab="Zeit", ylab=expression("RR-Intervalle ["~s~"]"), xaxt="n", yaxt="n", xlim=xlim, col=1)

  # Plot ticks and vertical lines
  marker <- c(start.rr, end.rr)
  axis(1, at=marker, label=format(c(end - 5 * 60, end), "%H:%M:%S"))
  axis(2, at=seq(.2, .6, .02), labels=seq(.2, .6, .02))
  axis(3, at=marker, label=rep("", length(marker)))
  axis(4, at=seq(.2, .6, .02), labels=rep("", length(seq(.2, .6, .02))))
  abline(v=c(min(t), max(t)), lty = "dashed", col="darkgrey")

  # Plot box again
  box()

  # Add reference letter  
  mtext("D", 4, line=2)

  # Clean up
  rm(ecg.data.file.path, ecg.data, kubios.hrv.data.path, kubios.hrv.data, ends, end, end.rr, isIn, marker, rr.interval, starts, start, start.rr, t, time, times, times.subset, xlim, y)
```

Nach der Berechnung der RR-Intervalle analysierte ich die \ac{HRV} in R mit Hilfe des Package RHRV \citep{Rodriguez-Linares2010}. Im ersten Schritt filterte ich die RR-Intervalle mit der in RHRV integrierten Filterfunktion. Sie implementiert einen Algorithmus, der einen adaptiven Grenzwert nutzt, um RR-Intervalle abzulehnen oder zu akzeptieren. Der Algorithmus vergleich den gegenwärtigen RR-Intervall mit dem vorherigen RR-Intervall, dem nachfolgenden RR-Intervall und einem Mittel der letzten 50 RR-Intervalle. Der Unterschied zwischen den drei Vergleichen darf für eine Akzeptanz nicht mehr als 13% betragen. Zusätzlich muss der gegenwärtige RR-Intervall zwischen einem Maximalwert und Minimalwert von drei Standabweichungen vom Mittel liegen, damit die Funktion ihn nicht herausgefiltert (wie bei \citet{DeManzano2010}). Im nächsten Schritt interpolierte ich linear (4 Hz) die RR-Intervalle, damit ein gleicher zeitlicher Abstand zwischen den Datensätzen gewährleistet ist. 

Ein Grundproblem der \ac{HRV}-Analyse unter sportlicher Belastung ist die Nichtstationarität des Herzfrequenzsignals (RR-Intervalle). Aus diesem Grund empfehlen \citet[S. 113]{Sarmiento2013} traditionelle Methoden der Spektralanalyse wie die \ac{FFT} nicht zu verwenden. Auch \citet[S. 61]{Hoos2010} schreibt von Autoren, die argumentieren, dass für hohe Intensitäten Ergebnisse der traditionellen Spektralanalyse der \ac{HRV} im Allgemeinen und insbesondere der absoluten Einheiten zur Beschreibung der autonomen Funktion unter sportlicher Belastung kaum geeignet sind. Sie führen dies einerseits auf methodische Probleme wie der belastungsbedingten Nichtstationarität und andererseits auf ihre mangelnde Vergleichbarkeit mit Ergebnissen unter schwachen Intensitäten zurück. Vgl. \citet[S. 61]{Hoos2010} lässt sich die gewohnte belastungsinduzierte Verschiebung von der vagalen zur sympathikotonen Dominanz oftmals nicht feststellen. 

Daraus folgt laut \citet[S. 61f.]{Hoos2010} die Forderung deutlich adäquaterer Methoden einzusetzen. Zu diesen Methoden gehören alternative Spektralanalysemethoden (z. B. Coarse Graining Spektralanalyse (CGSA), Kurzzeitfourier-Analyse (STFT) oder kontinuierliche Wavelet Transformation (CWT)) oder nicht-linearer Verfahren (insbesondere Detrended Fluctuation Analysis (DFA), Sampie Entropie (SampEn)). Bei der Nutzung von alternativen Spektralanalysemethoden unter sportlicher Belastung fordern die von \citet[S. 62]{Hoos2010} zitierten Wissenschaftler die Verwendung von einer belastungsadäquaten Erweiterung des HF-Spektralbands mindestens bis zur maximalen Atemfrequenz ($\sim$1 Hz). Des Weiteren fordern sie eine Abkehr von der bisherigen Interpretation der Spektralbändern, da sich im \ac{HF}-Band bei sportlicher Belastung vor allem mechanisch bedingte Resonanz- und Kopplungsphänomene mit der Atmung und der motorischen Aktivität zu manifestieren scheinen. 

Aufgrund der vorgestellten Forderungen verwende ich eine \ac{WT} zur Spektralanalyse. Die \ac{WT} ist ein leistungsfähiges Werkzeug zur Analyse von nichtstationären Signalen wie der Zeitreihe der RR-Intervalle. Die Analyse basiert auf einem Mutter-Wavelet. Das Mutter-Wavelet ist eine lokalisierte, oszillierende, reguläre Funktion $\psi(t)$. Wavelet-Funktionen sind anders als die Sinusfunktionen, auf der die \ac{FFT} basiert, im Raum lokalisiert. Dadurch erhält die \ac{WT} die zeitliche und spektrale Dimension. Für die Analyse nichtstationärer Signale ist damit vgl. \citet[S. 207]{Rodriguez-Linares2010} die \ac{WT} der \ac{FFT} vorzuziehen.

Die Verwendung der \ac{WT} ermöglicht die detaillierte Bewertung der Entwicklung der Herzreaktion in der Zeit, in der sich der Organismus auf die Intensität des Laufens, aber vermutlich auch auf die Zustandsveränderung im Flow einrichtet. Die Veränderungen der \ac{HRV}-Signalenergie (Gesamt, \ac{LF} und \ac{HF}-\ac{VHF}) versuche ich als Merkmal für die unterbrechungsfreie Flow-Diagnostik nutzen. Dabei verwende ich die folgenden Signalbänder: \ac{LF} 0.04 - 0.15 Hz; \ac{HF}-\ac{VHF} 0.15 - 1 Hz

Die \ac{WT} führe ich in R mit der Hilfe des RHRV Packages durch. In RHRV implemtierten \citet{Rodriguez-Linares2010} eine Maximal Overlap Discrete Wavelet Packet Transform (MODWPT). Zur Analyse stehen mehrere Wavelet-Funktion mit unterschiedlichen Längen zur Verfügung. Allgemein besitzen kürzere Wavelet-Funktionen eine bessere zeitliche Auflösung, aber eine schlechtere Frequenzauflösung. Auf der anderen Seite, besitzen längere Wellen in der Regel schlechtere zeitliche Auflösung, aber bieten eine bessere Frequenzauflösung. Bessere zeitliche Auflösung ermöglicht es, kürzere Zeitabständen zu studieren. Ich verwende deshalb ein asymmetrische Daubechies Wavelet der Länge 8 (la8), das laut \citet{Rodriguez-Linares2010} einen guten Kompromiss zwischen Frequenz- und Zeitauflösung bietet.

Zur Berechung der üblichen Spektralleistung der unterschiedlichen Bänder in $ms^2$ berechne ich das Mittel der Wavelet Koeffizienten. Die daraus resultierenden HRV-Merkmale des Laufes vom Donnerstag, den 31. Oktober 2013 bildet Tabelle \ref{tab:hrv-ergebisse} ab.

```{r hrv-merkmale, echo=FALSE, message=FALSE, results="asis"}
  
  # Subset features
  hrv.features.subset   <- hrv.features[start.time + 60 * 60 * 24 > as.POSIXct(hrv.features[,13], tz="CET") & as.POSIXct(hrv.features[,13], tz="CET") > start.time, c(1:9)]

  table.data                <- t(hrv.features.subset)
  colnames(table.data)  <- c("Baseline", "Nach 15 Min.", "Nach 30 Min.", "Nach 45 Min.", "Nach 60 Min.")
  rownames(table.data)  <- c("Mittlere Herzrate (BPM)", "LF ($ms^2$)", "HF-VHF ($ms^2$)", "Gesamt ($ms^2$)", "LF (\\%)", "HF (\\%)", "LF (n. u.)", "HF-VHF (n. u.)", "LF/HF-VHF")
  table.data            <- xtable(table.data, caption = paste("Ergebnisse vom", strftime(start.time, format = "%A, den %d. %B %Y")), align = "lrrrrr", label = "tab:hrv-ergebisse")

  print(table.data, caption.placement = "top", sanitize.rownames.function = function(x){x}, comment=FALSE)
  
  rm(table.data)
```

<!--
Warum LF und HF?

One particular approach to analyze HRV is to use spectral methods that provide information about how variance in HR ("power") distributes as a function of frequency (Task Force Guidelines, 1996). One of the relevant parameters in spectral analyses is the high-frequency component of the heart rate variability (HF-HRV), which reflects variance in the high frequency range (0.15-0.4 Hz). HF-HRV has been shown to be a reliable indicator for parasympathetic efferent activity (Porges, 1995) and increased task demands are related to a low level of HF-HRV (Backs et al., 1991; Mulder et al., 2002). Furthermore, increased HF-HRV is associated with efficient use of strategies for self-regulation and attention, which results in better performance in cognitive tasks (better accuracy and shorter reaction time) (Hansen et al, 2003; Thayer et al., 2009). In contrast, decreased HF-HRV is related to limited use of self-regulatory strategies (Thayer & Brosschot, 2005), for example, failure to recognize task relevant information or to habituate to novel, non-relevant stimuli (hypervigilance; Friedman, 2007; Thayer, Friedman, Borkovec, Johnsen, & Molina, 2000; Thayer et al., 2009). Focusing on task relevant stimuli and fading out task-irrelevant information are key components of flow. Therefore, one can assume a positive relation between flow and HF-HRV. However, prior studies suggest that moderate and increased task demands are related to lower levels of HF-HRV (Backs et al., 1991; Jorna, 1992; Mulder et al., 2002 Vicente et al., 1987). Based on these findings, we hypothesize a relation between flow and HF-HRV without making any assumptions regarding the direction of the relationship. Another parameter of HRV is the low-frequency component of the HRV (LF-HRV), which reflects the variance in the low frequency range (0.04-0.15 Hz) of heart rates. The meaning of this parameter is controversial in recent research. LF-HRV has been used as an indicator for sympathetic activity (Pagani et al., 1986; Malliani, Pagani, Lombardi, & Cerutti, 1991). However, a growing body of research disproved this assumption and showed that LF-HRV rather reflects baroreflex modulation (Heathers, 2014; Rahman, Pechnik, Gross, Sewall, Goldstein, 2011; Schroeder et al., 2003). The baroreflex is one of the elementary mechanisms through which acute changes in the heart rate and blood pressure is controlled (Guyton, 1980) Baroreflex activity has been associated with several cognitive functions such as mental stress (del Paso, Langewitz, Robles, & Pérez, 1996; Robbe et al., 1987, Steptoe & Sawada, 1989), cognitive-attentional demands (del Paso, González, & Hernández, 2004), and cognitive performance (Yasumasu, del Paso, Takahara, & Nakashima, 2006). According to Lacey's intake/rejection hypothesis (Lacey & Lacey, 1970), tasks containing cognitive elaboration are related to a baroreceptor-elicited cardiac acceleration (del Paso et al., 2004). In contrast, activities involving the detection of external stimuli are related to a baroreceptor-modulated cardiac deceleration (Bernardi, Porta, Spicuzza, & Sleight, 2005). Yasumasu et al. (2006) showed that activities that involve cognitive elaboration and rejection of external stimuli cause a decrease of baroreflex activity, which in turn causes an increase in cardiovascular activity (i.e., increase in heart rate). Cognitive involvement in an activity and rejection of external stimuli are crucial for experiencing flow. Furthermore, previous research suggests an inverted u-shaped function between flow and LF-HRV (Peifer et al., 2014b). Based on these results, we assume a relation between LF-HRV (as an indicator for baroreflex function) and flow experience and test this assumption in an experimental setting that addresses the aforementioned limitations of previous studies.
-->

```{r examine-features, echo=FALSE, message=FALSE, warning=FALSE, eval=FALSE}

  fss.features.subset <- fss.features[,c(1,3,5,7,9,11,12,15)]
  hrv.features.subset <- hrv.features[, c(1:11, 15)]
  
  par(mfrow = c(1,2))
  for(i in 1:5) {
    plot(fss.features.subset[fss.features.subset[, 6] == "Running",i], pch=19, col=fss.features.subset[fss.features.subset[, 6] == "Running",]$measurement, ylab = names(fss.features.subset[fss.features.subset[, 6] == "Running",])[i])
    boxplot(fss.features.subset[fss.features.subset[, 6] == "Running",i] ~ measurement, data=fss.features.subset[fss.features.subset[, 6] == "Running",])
    }

  par(mfrow = c(1,1))
  for(i in 1:5) {
    hist(fss.features.subset[fss.features.subset[, 6] == "Running",i], main = names(fss.features.subset[fss.features.subset[, 6] == "Running",])[i], xlab = names(fss.features.subset[fss.features.subset[, 6] == "Running",])[i])
    lines(density(fss.features.subset[fss.features.subset[, 6] == "Running",i]))
    rug(jitter(fss.features.subset[fss.features.subset[, 6] == "Running",i]))
    } 
  
  par(mfrow = c(1,2))
  for(i in 1:9) {
    plot(hrv.features.subset[hrv.features.subset[, 10] == "Running",i], pch=19, col=hrv.features.subset[hrv.features.subset[, 10] == "Running",]$measurement, ylab = names(hrv.features.subset[hrv.features.subset[, 10] == "Running",])[i])
    boxplot(hrv.features.subset[hrv.features.subset[, 10] == "Running",i] ~ measurement, data=hrv.features.subset[hrv.features.subset[, 10] == "Running",])
    }
  
  par(mfrow = c(1,1))
  for(i in 1:9) {
    hist(hrv.features.subset[hrv.features.subset[, 10] == "Running",i], main = names(hrv.features.subset[hrv.features.subset[, 10] == "Running",])[i], xlab = names(hrv.features.subset[hrv.features.subset[, 10] == "Running",])[i])
    lines(density(hrv.features.subset[hrv.features.subset[, 10] == "Running",i]))
    rug(jitter(hrv.features.subset[hrv.features.subset[, 10] == "Running",i]))
    } 

  # Beobachtung
  # Lauf vom 7.11.2013 - 3 - Mittlere HR; hoher Absorbiertheit
  # Lauf vom 7.11.2013 - 4 - Sehr hohe HR; niedrige Absorbiertheit
  # Lauf vom 24.10.2014 - 3 u. 4 - Sehr niedrige HFnu und ansteigende HR
  
  # Keine Normalverteilung haben (visuell): anxiety, fit, lf.a.power, hf.a.power

  # Modify m 
  features[features[, 1] != 1, ][,1] = 2

  getSigString <- function(p) {
      sig.string <- "   "
      if (p < .1)
        sig.string <- ".  "
      if (p < .05)
        sig.string <- "*  "
      if (p < .01)
        sig.string <- "** "
      if (p < .001)
        sig.string <- "***"
      return(sig.string)
    }
  
  # Result table
  table.data <- data.frame(stringsAsFactors = FALSE)

  #######
#   measure.5 <- features[features$m == 5,]
# 
#   # Testen auf Normalverteilung
#   shapiro.test(measure.5$anxiety)
  #######

  for (i in 2:ncol(features)) {
#     boxplot(features[,i]  ~ m, data = features, title = colnames(features)[i])
    
    # Calculate feature values
    features  <- features[,c(1, i)]
    means     <- aggregate(features[, 2], list(features[, 1]), function(x) {mean(x, na.rm = T)})
    sds       <- aggregate(features[, 2], list(features[, 1]), function(x) {sd(x, na.rm = T)})
    
    # Create anova structure
    features.stack    <- stack(features)
    m                 <- rep(features.stack[1:nrow(features), 1], ncol(features) - 1)
    features.stack    <- features.stack[(nrow(features) + 1):nrow(features.stack),]
    features.stack[3] <- as.factor(m)                   
    rm(m)                               
    colnames(features.stack) = c("value", "feature", "m")
  
    # Get p value
    fit <- aov(value ~ m, data=features.stack)
    p   <- summary(fit)[[1]][["Pr(>F)"]][1]
    p   <- paste(sprintf("%.2f", round(p, 2)), getSigString(p))
    
    # Store values
    row <- data.frame(means[1, 2], sds[1, 2], means[2, 2], sds[2, 2], p)
    table.data <- rbind(table.data, row)

#     tukey <- TukeyHSD(fit)
#     print(tukey)
    
    features          <- features.backup
    features[features[, 1] != 1, ][,1] = 2
  }

  rownames(table.data)  <- c("Generalfaktor", "Glatter Verlauf", "Absorbiertheit", "Besorgnis", "AFP", "Mittlere Herzrate (BPM)", "LF ($ms^2$)", "HF-VHF ($ms^2$)", "Total ($ms^2$)", "LF (\\%)", "HF (\\%)", "LF (n. u.)", "HF-VHF (n. u.)", "LF/HF-VHF")
  addtorow          <- list()
  addtorow$pos      <- list()
  addtorow$pos[[1]] <- 0
  addtorow$pos[[2]] <- 0
  addtorow$command <- c("& \\multicolumn{2}{c}{Baseline} & \\multicolumn{2}{c}{Laufen} & \\\\\n", "& \\multicolumn{1}{c}{M} & \\multicolumn{1}{c}{SD} & \\multicolumn{1}{c}{M} & \\multicolumn{1}{c}{SD} & \\multicolumn{1}{c}{P} \\\\\n")
  table.data            <- xtable(table.data, caption = "Unterschied zwischen Baseline-Messungen und Laufmessungen", label = "tab:baseline-laufen", align = "lrrrrl")

  print(table.data, caption.placement = "top", sanitize.rownames.function = function(x){x}, comment=FALSE, add.to.row = addtorow, include.colnames = FALSE)
  
  # Clean up
  rm(features, features.stack, means, row, sds, fit, i, p)
```

<!-- Unterschied zwischen Baseline-Messungen und Laufmessungen -->

<!-- Um zu testen, ob ein Unterschied zwischen den erhobenen Merkmalen aus den Baseline-Messungen und den Laufmessungen besteht, führte ich eine einfaktorielle Varianzanalyse (ANOVA) für jedes Merkmal durch. Das Ergebnis zeigt, dass alle Merkmale, außer dem Generalfaktor und dem Besorgnisfaktor, sich mindestens signifikant zwischen Baseline-Messungen und Laufmessungen unterscheiden (siehe Tabelle \ref{tab:baseline-laufen}). Das Ergebnis unterstützt meine Entscheidung Absorbiertheit als Maßzahl zu benutzen. -->

\bibliographystyle{agsm}
\bibliography{./bibtex/library}