---
title: 'Studie: Flow beim Laufen'
author: "Simon Bogutzky"
date: "April 2015"
output:
  pdf_document:
    fig_caption: yes
    keep_tex: yes
header-includes: \usepackage{graphicx} \usepackage[printonlyused,withpage]{acronym}
  \usepackage{natbib}
---

# Abkürzungsverzeichnis

\begin{acronym}[TDMA]
  \acro{AFP}{Anforderungs-Fähigkeits-Passung}
  \acro{ANS}{autonome Nervensystem}
	\acro{EKG}{Elektrokardiogramm}
	\acro{ESM}{Experience Sampling Method}
	\acro{FKS}{Flow-Kurzskala}
	\acro{GPS}{Global Positioning System}
	\acro{HRV}{Herzratenvariabilität}
\end{acronym}

# Ziel
Die Studie diente dazu statistische Beziehungen zwischen:

* Flow und der Aktivität des autonomen Nervensystems
* Flow und dem Bewegungsfluss

beim Laufen herzustellen. Des Weiteren suchte ich in den Daten nach markanten Mustern, die den Eintritt in den Flow, Flow selbst und den Austritt aus dem Flow markieren.

# Methode
## Flow-Diagnostik
### Flow-Kurzskala

Zur subjektiven Erfassung des Flow-Erlebens kam die \ac{FKS} von \citet{Rheinberg2003} zum Einsatz. Die \ac{FKS} besteht aus insgesamt 16 Items. Die ersten zehn Items bilden anhand einer 7-Punkte-Likert-Skala ("trifft nicht zu" = 1 bis "trifft zu" = 7) Komponenten des Flow-Erlebens ab und man fasst sie als Generalfaktor zusammen. Zur weiteren Differenzierung des Flow-Konstrukts ist der Generalfaktor der \ac{FKS} in zwei Faktoren (Subdimensionen) unterteilt worden. Faktor I umfasst dabei sechs Items, die durchweg Aussagen zum "Glatten automatisierten Verlauf" einer Handlung beschreiben. Faktor II beinhaltet vier Items, die mit "Absorbiertheit" in Zusammenhang stehen. Der Reliabilitätskoeffizient der zehn Items im Generalfaktor (Cronbachs Alpha) liegt nach Angaben von \citet[S. 9]{Rheinberg2003} im Bereich um $\alpha = 0.90$. Da nicht damit zu rechnen ist, dass in Anforderungssituationen ausschließlich Flow entsteht, sondern auch Angst und Besorgnis ausgelöst werden kann, wurde die \ac{FKS} durch eine "Besorgniskomponente" erweitert. Diese besteht aus drei Items (Nr. 11 bis 13, Cronbachs $\alpha = 0.80$ bis $\alpha = 0.90$). Am Ende der \ac{FKS} nehmen die Probanden noch drei Einschätzungen zur \ac{AFP} (auf einer 9-Punkte-Skala) vor. Dabei fokussiert das Item 14 auf einen Vergleich der Schwierigkeit der jetzigen Tätigkeit mit allen anderen Tätigkeiten (leicht vs. schwer) und das Item 15 auf die eigene Leistungsfähigkeit (niedrig vs. hoch). Das Item 16 fragt direkt, auf die aktuelle Tätigkeit (hier also Laufens) bezogen, nach der subjektiv wahrgenommenen \ac{AFP} (zu gering vs. zu hoch). 

## Untersuchungsdesign 
Ein männlicher Freizeitläufer (29) nahm am Experiment teil. Er lief in sechs aufeinanderfolgenden Wochen an einem Tag 60 Minuten jeweils die gleiche Strecke und zur gleichen Tageszeit.

Vor jedem Lauf rüstete ich ihn mit einem geladenen Smartphone, einem passenden Smartphone-Armband, zwei geladenen Bewegungssensoren, einem geladenen \ac{EKG}-Sensoren und vier Elektroden aus. Die Anordnung des Equipments ist Abbildung \ref{fig:anordnung-des-equipments} zu entnehmen.

\begin{figure}[htbp]
\centering
\includegraphics[keepaspectratio,width=0.75\textwidth]{./figures/equipment-arrangement.pdf}
\caption{Anordnung des Equipments}
\label{fig:anordnung-des-equipments}
\end{figure}

Während jedes Laufes nutzte ich die dafür eigens entwickelte mobile Datenaufnahme App, um \ac{EKG} und Bewegungsdaten mit Hilfe der tragbaren Sensoren des Unternehmens Shimmer Research (Shimmer 2r) aufzuzeichnen. Die Datenaufnahme App läuft auf dem Android OS ab Version 4.4 und kommuniziert mit den Sensoren über Bluetooth. Die Bewegungssensoren besitzen einen Beschleunigungsmesser und ein Kreiselinstrument, die beide auf jeweils drei Achsen messen. Für das Experiment nutzte ich das Smartphone Samsung Galaxy Nexus, welches auch über einen Beschleunigungsmesser und ein Kreiselinstrument verfügt. Alle Bewegungssensoren arbeiten mit einer Datenrate von 100 Hz. Der \ac{EKG}-Sensor von Shimmer Research arbeitet mit vier Ableitungen. Im Experiment nutzte ich Knopfelektroden und eine Datenrate von 204.8 Hz. Alle 15 Minuten während jedes Laufes forderte die Datenaufnahme App mit einem Signal den Läufer auf, eine \ac{FKS} auszufüllen. Vor jedem Lauf führte der Läufer eine 15-minütige Baseline Messung durch. 

Nach jedem Lauf übertrug ich die gesammelten Daten für die software-technische Analyse auf meinen Arbeitsrechner. Die Daten bestehen für jeden Lauf aus kontinuierlichen \ac{EKG}-Daten, \ac{GPS}-Positionen, Beschleunigungen und Winkelgeschwindigkeiten von den Körperpositionen Bein, Arm und Handgelenk. 

### Datenverarbeitung
#### Flow-Kurzskala
Aus den Fragebogen Daten berechnete die Faktoren der \ac{FKS}. In Tabelle \ref{tab:fks-merkmale} sind die Ergebnisse der \ac{FKS} des Laufes vom Donnerstag, den 31. Oktober 2013 dargestellt. In diesem Lauf z. B. steigt die \ac{AFP} kontinuirlich und am Ende des Laufes bewertet der Läufer sein Flow-Erleben am höchsten. 

```{r calculate-fss-features, echo=FALSE, message=FALSE, warning=FALSE}
  library("flow")
  
  # Set start time
  start.time <- as.POSIXct(strptime("2013-10-31--18-11-26", "%Y-%m-%d--%H-%M-%S"), tz="CET")
  
  # Set file path 
  file.path <- paste("./data/", format(start.time, format="%Y-%m-%d--%H-%M-%S", tz="CET"), "/", sep="")
  
  # Load fss data
  fss.data  <- read.csv(paste(file.path, "fss-data.csv", sep=""), header=T)
  
  # Calculate fss features
  fss.features  <- data.frame()
  for(i in 1:nrow(fss.data)) {
    start       <- as.POSIXct(fss.data[i, 17]/1000, origin="1970-01-01", tz="CET")
    end         <- as.POSIXct(fss.data[i, 18]/1000, origin="1970-01-01", tz="CET")
    fss.results <- CalculateFlowShortScaleResults(c(t(fss.data[i, 1:16])), start=start, end=end)
    
    # Extract flow features
    for(j in 1:length(fss.results[[1]][[1]])) {
      fss.features <- rbind(fss.features, data.frame(fss.results[[1]][[1]][[j]], fss.results[[1]][[2]][[j]], format(start, format="%Y-%m-%d %H:%M:%S", tz="CET"), format(end, format="%Y-%m-%d %H:%M:%S", tz="CET"), j))
    } 
  }
  colnames(fss.features)  <- c("m", "sd", "start", "end", "feature")
  fss.features[,5]        <- as.factor(fss.features[,5])
  
  # Clean up
  rm(fss.results)
```

\begin{table}
\caption{Ergebnisse vom `r strftime(start.time, format = "%A, den %d. %B %Y")`}
\label{tab:fks-merkmale}
\centering
```{r fks-merkmale, echo=FALSE, message=FALSE, results="asis"}
  library(tables)
  table.data            <- fss.features[,c(1:3, 5)]
  table.data[,3]        <- factor(table.data[,3], levels(table.data[,3]), labels = c("Baseline", "Nach 15 Min.", "Nach 30 Min.", "Nach 45 Min.", "Nach 60 Min."))
  table.data[,4]        <- factor(table.data[,4], levels(table.data[,4]), labels = c("Generalfaktor", "glatter Verlauf", "Absorbiertheit", "Besorgnis", "AFP"))
  colnames(table.data)  <- c("M", "SD", "Beginn", "Merkmal")
  tabular.data          <- tabular(Heading()*Merkmal ~ Heading()*Beginn*(`M` +`SD`)*Heading()*(identity)*Format(digits=2), data=table.data)
  latex(tabular.data)
  rm(tabular.data)
```
\end{table}

Als Maßzahl nutze ich die zweite Subdimension \ac{FKS}, da Absorbiertheit laut \citet{Peifer2014} nur eintritt, wenn Anforderungen und Fähigkeiten sich in Balance befinden — somit ist sie ausschließlich im *Flow-Kanal* anzutreffen und deshalb ein repräsentativer Indikator für Flow als der Generalfaktor, der sich aus den zwei Subdimension zusammensetzt. Den Beleg hierfür geben \citet[S. 69]{Rheinberg2003a} in ihrer Studie. Sie stellten fest, dass Unterforderung keinen Einfluss auf den glatten Verlauf hat, jedoch die Absorbiertheit negativ beeinflusst. 

```{r bewertete-absorbiertheit, echo=FALSE, warning=FALSE, dev='pdf', fig.height=2.5, fig.width=6.5, fig.pos='htbp', fig.cap='Bewertete Absorbiertheit'}
  par(mfcol=c(1, 1), mar=c(3.5, 3.5, 1.5, 3.5) + 0.1, mgp=c(2, .5, 0), las=1, cex.axis=0.8, tck=.01, cex.lab=.8)
  
  # Plot data
  plot(table.data[fss.features[,5] == 3, 1], type="b", xlab ="Zeitpunkt", ylab="Absorbiertheit", pch=21, ylim=c(3, 6), xaxt="n", yaxt="n")

  # Plot ticks
  axis(1, at=1:5, label=table.data[fss.features[,5] == 3, 3])
  axis(2, at=seq(3, 6, .5), labels=seq(3, 6, .5))
  axis(3, at=1:5, label=rep("", length(1:5)))
  axis(4, at=seq(3, 6, .5), labels=rep("", length(seq(3, 6, .5))))

  # Plot box again
  box()
```

#### HRV-Analyse
Von den \ac{EKG}-Daten entfernte ich die Zeiten für die Befragung und erhielt jeweils 15-Minuten Abschnitte. Diese 15-Minuten Abschnitte las ich in Kubios \ac{HRV} (Version 2.1) ein. Kubios \ac{HRV} automatische R-Spitzen-Erkennung erkennt die meisten Herzschläge. Trotzdem ist eine manuelle Nachbearbeitung notwendig. Nicht erkannte Herzschläge fügte ich hinzu und zuviel erkannte Herzschläge entfernte ich. \ac{EKG}-Daten mit mehr als 2% an Artefakten habe ich aus der Datensammlung entfernt.

```{r subset-ecg-data, echo=FALSE, message=FALSE, warning=FALSE, eval=FALSE}

  # Load ecg data 
  ecg.data  <- read.csv(paste(file.path, "/ecg-data.csv", sep=""), header=T)
  
  # Set function attributes
  starts    <- c(start.time, as.POSIXct(strptime(fss.features[fss.features[,5] == 3, 4][1:4], "%Y-%m-%d %H:%M:%S"), tz="CET"))
  ends      <- c(as.POSIXct(strptime(fss.features[fss.features[,5] == 3, 3], "%Y-%m-%d %H:%M:%S"), tz="CET"))
  times     <- as.POSIXct(ecg.data[, 4]/1000, origin="1970-01-01", tz="CET")
  file.name <- "ecg-data"
  
  # Write subset in csv files
  WriteDataSubsetInCSVFile(ecg.data, times, starts, ends, file.name=file.name, file.path=file.path)
  
  # Clean up
  rm(file.name)
```

```{r calculate-hrv-features, echo=FALSE, message=FALSE, warning=FALSE}
  library(RHRV)
  
  # Create feature vector
  hrv.features <- c()

  # HRV file indexes
  hrv.file.index <- c(1, 2, 3, 4, 5)

  for (j in hrv.file.index) {
    
    if(!is.na(j)) {
    
        # Set hrv file name
        hrv.file.name <- paste(file.path, "ecg-data-", j, "_hrv.txt", sep="")
        
        # Load Kubios HRV txt data
        hrv.kubios.data   <- read.csv(hrv.file.name, header = F, na.strings = "", fill = T, skip = 97, col.names = c("NA1", "Time", "RRInterval", "FFTFrequency", "FFTPSD", "ARFrequency", "ARPSD", "NA2", "NA3", "NA4", "NA5"))
        
        # Get time and rr-intervals
        time              <- hrv.kubios.data$Time
        time              <- time[complete.cases(time)]
        rr.interval       <- hrv.kubios.data$RRInterval
        rr.interval       <- rr.interval[complete.cases(rr.interval)]
        
        # Create hrv data of 10 minutes of the end of the whole data
        hrv.data          <- CreateHRVData()
        hrv.data          <- SetVerbose(hrv.data, FALSE)
        hrv.data$Beat     <- data.frame("Time"=time[time >= time[length(time)] - 60 * 10])
        
        # Build not interpolated heart rates
        hrv.data          <- BuildNIHR(hrv.data)
        #PlotNIHR(hrv.data)
        
        # Remove artefact manually
        #hrv.data          <- EditNIHR(hrv.data)
        #PlotNIHR(hrv.data)
        
        # Filter niHR
        s                 <- sd(hrv.data$Beat$niHR)
        m                 <- mean(hrv.data$Beat$niHR)
        minbpm            <- m - 3 * s
        maxbpm            <- m + 3 * s
        hrv.data          <-  FilterNIHR(hrv.data, long=50, last=13, minbpm=minbpm, maxbpm=maxbpm)
        #PlotNIHR(hrv.data)
        
        # Linear Interpolate the data by 4 Hz (default)
        hrv.data          <- InterpolateNIHR(hrv.data)
        #PlotHR(hrv.data)
        
        # Create time analysis
        #hrv.data          <- CreateTimeAnalysis(hrv.data, size=60)
        
        # Plot spectogram with Short-time Fourier transform 30 seconds window with 1 second shift for LF
        #PlotSpectrogram(hrv.data, size=30, shift=1, freqRange=c(0.04, 0.15))
        
        # Plot spectogram with Short-time Fourier transform 30 seconds window with 1 second shift for HF-VHF
        #PlotSpectrogram(hrv.data, size=10, shift=1, freqRange=c(0.15, 1))
        
        # Create Frequency analysis (CWT) with least asymmetric Daubechies of width 8 for ULF, VLF, LF and (HF + VHF) as HF 
        hrv.data          <- CreateFreqAnalysis(hrv.data)
        hrv.data          <- CalculatePowerBand(hrv.data, indexFreqAnalysis=1, type="wavelet", wavelet="la8", bandtolerance=0.005, ULFmin=0, ULFmax=0.0033, VLFmin=0.0033, VLFmax=0.04, LFmin=0.04, LFmax=0.15, HFmin=0.15, HFmax= 1)
        
        # Plot bands
        #PlotPowerBand(hrv.data, indexFreqAnalysis=1, hr=TRUE)
        
        # Calculate HRV features
        ulf.power.a       <- mean(hrv.data$FreqAnalysis[[1]]$ULF)
        vlf.power.a       <- mean(hrv.data$FreqAnalysis[[1]]$VLF)
        lf.power.a        <- mean(hrv.data$FreqAnalysis[[1]]$LF)
        hf.power.a        <- mean(hrv.data$FreqAnalysis[[1]]$HF)
        total.power       <- ulf.power.a + vlf.power.a + lf.power.a + hf.power.a
        ulf.power.r       <- ulf.power.a/total.power * 100
        vlf.power.r       <- vlf.power.a/total.power * 100
        lf.power.r        <- lf.power.a/total.power * 100
        hf.power.r        <- hf.power.a/total.power * 100
        lf.power.nu       <- lf.power.a/(lf.power.a + hf.power.a) * 100
        hf.power.nu       <- hf.power.a/(lf.power.a + hf.power.a) * 100
        lfhf              <- lf.power.a/hf.power.a
        mean.hr           <- mean(hrv.data$HR)
        
        # Add features to feature vector
        hrv.features      <- c(hrv.features, mean.hr, lf.power.a, hf.power.a, total.power, lf.power.r, hf.power.r, lf.power.nu, hf.power.nu, lfhf)
        
        # Clean up
        rm(ulf.power.a, vlf.power.a, lf.power.a, hf.power.a, total.power, ulf.power.r, vlf.power.r, lf.power.r, hf.power.r, lf.power.nu, hf.power.nu, lfhf, mean.hr)
      } else {
        # Calculate HRV features
        ulf.power.a       <- NA
        vlf.power.a       <- NA
        lf.power.a        <- NA
        hf.power.a        <- NA
        total.power       <- NA
        ulf.power.r       <- NA
        vlf.power.r       <- NA
        lf.power.r        <- NA
        hf.power.r        <- NA
        lf.power.nu       <- NA
        hf.power.nu       <- NA
        lfhf              <- NA
        mean.hr           <- NA
        
        # Add features to feature vector
        hrv.features      <- c(hrv.features, mean.hr, lf.power.a, hf.power.a, total.power, lf.power.r, hf.power.r, lf.power.nu, hf.power.nu, lfhf)
      }
  }
  
  # Make data frame
  dimnames      <- list(row=c("mean.hr", "lf.power.a", "hf.power.a", "total.power", "lf.power.r", "hf.power.r", "lf.power.nu", "hf.power.nu", "lfhf"), col=1:i)
  hrv.features  <- as.data.frame(t(matrix(hrv.features, ncol=i, nrow=9, dimnames=dimnames)))

  # Clean up
  rm(j, s, m, minbpm, maxbpm, hrv.kubios.data, dimnames)
```

```{r ekg-signalverarbeitung, echo=FALSE, warning=FALSE, dev='CairoPNG', dpi=800, fig.height=4.5, fig.width=6.5, fig.pos='htbp', fig.cap='EKG-Signalverarbeitung'}
  par(mfcol=c(4, 1), mar=c(3, 3, 1.5, 3) + 0.1, mgp=c(2, .5, 0), las=1, cex.axis=0.8, tck=.01, cex.lab=.8, xaxs="i", yaxs="i")

  # Load ecg data 
  ecg.data  <- read.csv(paste(file.path, "/ecg-data.csv", sep=""), header=T)
  
  # Set time properties
  starts    <- c(start.time, as.POSIXct(strptime(fss.features[fss.features[,5] == 3, 4][1:4], "%Y-%m-%d %H:%M:%S"), tz="CET"))
  ends      <- c(as.POSIXct(strptime(fss.features[fss.features[,5] == 3, 3], "%Y-%m-%d %H:%M:%S"), tz="CET"))
  times     <- as.POSIXct(ecg.data[, 4]/1000, origin="1970-01-01", tz="CET")
  
  # Set data
  t     <- ecg.data[, 1]
  y     <- ecg.data[, 3]
  end   <- ends[length(ends)]
  start <- starts[length(starts)]
  
  # Plot all ecg data
  plot(t, y, type="l", xlab="", ylab=expression("EKG LA LL ["~mV~"]"), xaxt="n", yaxt="n", col=1)
  par(new = T)
  plot(times, y, type="n", xlab="", ylab="", xaxt="n", yaxt="n")

  # Mark interesting part
  polygon(c(start, start, end, end), c(-10, 10, 10, -10), col = rgb(1, 1, 1, .2), border = rgb(0, 0, 0, 0))
  
  # Plot ticks and vertical lines
  axis(1, at=c(starts, ends), label=format(c(starts, ends), "%H:%M:%S"))
  axis(2, at=seq(-6, 6, 2), labels=seq(-6, 6, 2))
  axis(3, at=c(starts, ends), label=rep("", length(c(starts, ends))))
  axis(4, at=seq(-6, 6, 2), labels=rep("", length(seq(-6, 6, 2))))
  abline(v=starts, lty="dashed", col="grey")
  abline(v=ends, lty="dashed", col="grey")
  
  # Plot box again
  box()
  
  # Add reference letter  
  mtext("A", 4, line=2)

  # Plot the last 15 minutes of ecg data
  isIn         <- start - 30 <= times & end + 30 >= times
  t            <- t[isIn]
  y            <- y[isIn]
  times.subset <- times[isIn]
  
  plot(t, y, type="l", xlab="", ylab=expression("EKG LA LL ["~mV~"]"), xaxt="n", yaxt="n", col=1)
  par(new = T)
  plot(times.subset, y, type="n", xlab="", ylab="", xaxt="n", yaxt="n")

  # Plot ticks and vertical lines
  axis(1, at=c(starts, ends), label=format(c(starts, ends), "%H:%M:%S"))
  axis(2, at=seq(-6, 6, 2), labels=seq(-6, 6, 2))
  axis(3, at=c(starts, ends), label=rep("", length(c(starts, ends))))
  axis(4, at=seq(-6, 6, 2), labels=rep("", length(seq(-6, 6, 2))))
  abline(v=starts, lty="dashed", col="grey")
  abline(v=ends, lty="dashed", col="grey")

  # Plot box again
  box()

  # Add reference letter  
  mtext("B", 4, line=2)

  # Set data
  t         <- time
  y         <- rr.interval
  end.rr    <- max(t)
  start.rr  <- min(t)
  xlim      <- c(start.rr - 30, end.rr + 30)
  
  # Plot rrIntervals
  plot(t, y, type="l", xlab="", ylab=expression("RR-Intervalle ["~s~"]"), xaxt="n", yaxt="n", xlim=xlim, col=1)

  # Mark interesting part
  polygon(c(end.rr - 10 * 60, end.rr - 10 * 60, end.rr, end.rr), c(0, 1, 1, -0), col = rgb(1, 1, 1, .2), border = rgb(0, 0, 0, 0))

  # Plot ticks and vertical lines
  marker <- c(start.rr, end.rr - 10 * 60, end.rr)
  axis(1, at=marker, label=format(c(start, end - 10 * 60, end), "%H:%M:%S"))
  axis(2, at=seq(.25, .50, .05), labels=seq(.25, .50, .05))
  axis(3, at=marker, label=rep("", length(marker)))
  axis(4, at=seq(.25, .50, .05), labels=rep("", length(seq(.25, .50, .05))))
  abline(v=marker, lty = "dashed", col="grey")

  # Plot box again
  box()

  # Add reference letter  
  mtext("C", 4, line=2)

  # Set data
  t         <- hrv.data$Beat$Time
  y         <- hrv.data$Beat$RR / 1000
  end.rr    <- max(t)
  start.rr  <- min(t)
  xlim      <- c(start.rr - 30, end.rr + 30)
  
  # Plot rrIntervals
  plot(t, y, type="l", xlab="Zeit", ylab=expression("RR-Intervalle ["~s~"]"), xaxt="n", yaxt="n", xlim=xlim, col=1)

  # Plot ticks and vertical lines
  marker <- c(start.rr, end.rr)
  axis(1, at=marker, label=format(c(end - 10 * 60, end), "%H:%M:%S"))
  axis(2, at=seq(.25, .50, .025), labels=seq(.25, .50, .025))
  axis(3, at=marker, label=rep("", length(marker)))
  axis(4, at=seq(.25, .50, .025), labels=rep("", length(seq(.25, .50, .025))))
  abline(v=c(min(t), max(t)), lty = "dashed", col="grey")

  # Plot box again
  box()

  # Add reference letter  
  mtext("D", 4, line=2)

  # Clean up
  rm(ecg.data, end, end.rr, hrv.data, isIn, marker, rr.interval, start, start.rr, t, time, times, times.subset, xlim, y)
```

```{r hrv-merkmale, echo=FALSE, message=FALSE, results="asis"}
  library(xtable)  
  table.data            <- t(hrv.features)
  colnames(table.data)  <- c("Baseline", "Nach 15 Min.", "Nach 30 Min.", "Nach 45 Min.", "Nach 60 Min.")
  rownames(table.data)  <- c("Mittlere Herzrate (BPM)", "LF ($ms^2$)", "HF-VHF ($ms^2$)", "Total ($ms^2$)", "LF (\\%)", "HF (\\%)", "LF (n. u.)", "HF-VHF (n. u.)", "LF/HF-VHF")
  table.data            <- xtable(table.data, caption = paste("Ergebnisse vom", strftime(start.time, format = "%A, den %d. %B %Y")), align = "lrrrrr", label = "tab:hrv-ergebisse")

  print(table.data, caption.placement = "top", sanitize.rownames.function = function(x){x}, comment=FALSE)
```

```{r baseline-laufen-vergleich, echo=FALSE, message=FALSE, warning=FALSE, results="asis"}
  
  # Load feature data
  load("./data/features.RData")

  # Backup data
  features -> features.backup
  
  # Modify m 
  features[features[, 1] != 1, ][,1] = 2

  getSigString <- function(p) {
      sig.string <- "   "
      if (p < .1)
        sig.string <- ".  "
      if (p < .05)
        sig.string <- "*  "
      if (p < .01)
        sig.string <- "** "
      if (p < .001)
        sig.string <- "***"
      return(sig.string)
    }
  
  # Result table
  table.data <- data.frame(stringsAsFactors = FALSE)

  for (i in 2:ncol(features)) {
#     boxplot(features[,i]  ~ m, data = features, title = colnames(features)[i])
    
    # Calculate feature values
    features  <- features[,c(1, i)]
    means     <- aggregate(features[, 2], list(features[, 1]), function(x) {mean(x, na.rm = T)})
    sds       <- aggregate(features[, 2], list(features[, 1]), function(x) {sd(x, na.rm = T)})
    
    # Create anova structure
    features.stack    <- stack(features)
    m                 <- rep(features.stack[1:nrow(features), 1], ncol(features) - 1)
    features.stack    <- features.stack[(nrow(features) + 1):nrow(features.stack),]
    features.stack[3] <- as.factor(m)                   
    rm(m)                               
    colnames(features.stack) = c("value", "feature", "m")
  
    # Get p value
    fit <- aov(value ~ m, data=features.stack)
    p   <- summary(fit)[[1]][["Pr(>F)"]][1]
    p   <- paste(sprintf("%.2f", round(p, 2)), getSigString(p))
    
    # Store values
    row <- data.frame(means[1, 2], sds[1, 2], means[2, 2], sds[2, 2], p)
    table.data <- rbind(table.data, row)

#     tukey <- TukeyHSD(fit)
#     print(tukey)
    
    features          <- features.backup
    features[features[, 1] != 1, ][,1] = 2
  }

  rownames(table.data)  <- c("Generalfaktor", "Glatter Verlauf", "Absorbiertheit", "Besorgnis", "AFP", "Mittlere Herzrate (BPM)", "LF ($ms^2$)", "HF-VHF ($ms^2$)", "Total ($ms^2$)", "LF (\\%)", "HF (\\%)", "LF (n. u.)", "HF-VHF (n. u.)", "LF/HF-VHF")
  addtorow          <- list()
  addtorow$pos      <- list()
  addtorow$pos[[1]] <- 0
  addtorow$pos[[2]] <- 0
  addtorow$command <- c("& \\multicolumn{2}{c}{Baseline} & \\multicolumn{2}{c}{Laufen} & \\\\\n", "& \\multicolumn{1}{c}{M} & \\multicolumn{1}{c}{SD} & \\multicolumn{1}{c}{M} & \\multicolumn{1}{c}{SD} & \\multicolumn{1}{c}{P} \\\\\n")
  table.data            <- xtable(table.data, caption = "Unterschied zwischen Baseline-Messungen und Laufmessungen", label = "tab:baseline-laufen", align = "lrrrrl")

  print(table.data, caption.placement = "top", sanitize.rownames.function = function(x){x}, comment=FALSE, add.to.row = addtorow, include.colnames = FALSE)
  
  # Clean up
  rm(features, features.stack, means, row, sds, fit, i, p)
```

## Unterschied zwischen Baseline-Messungen und Laufmessungen

Um zu testen, ob ein Unterschied zwischen den erhobenen Merkmalen aus den Baseline-Messungen und den Laufmessungen besteht, führte ich eine einfaktorielle Varianzanalyse (ANOVA) für jedes Merkmal durch. Das Ergebnis zeigt, dass alle Merkmale, außer dem Generalfaktor und dem Besorgnisfaktor, sich mindestens signifikant zwischen Baseline-Messungen und Laufmessungen unterscheiden (siehe Tabelle \ref{tab:baseline-laufen}). Das Ergebnis unterstützt meine Entscheidung Absorbiertheit als Maßzahl zu benutzen.  

\bibliographystyle{agsm}
\bibliography{./bibtex/library}

```{r save-features, echo=FALSE, message=FALSE, warning=FALSE, eval=FALSE}
  
  # Append data
  if(file.exists("./data/features.csv")) {
    features <- read.csv("./data/features.csv")
    write.csv(rbind(features, cbind(fss.features, hrv.features)), "./data/features.csv", row.names=FALSE)
  } else {
    write.csv(cbind(fss.features, hrv.features), "./data/features.csv", row.names=FALSE)
  }
```