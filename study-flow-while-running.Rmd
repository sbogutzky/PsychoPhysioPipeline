---
title: 'Studie: Flow beim Laufen'
author: "Simon Bogutzky"
date: "April 2015"
output: pdf_document
---
# Ziel
Die Studie diente dazu statistische Beziehungen zwischen:

* Flow und der Aktivität des autonomen Nervensystems
* Flow und dem Bewegungsfluss

beim Laufen herzustellen. Des Weiteren suchte ich in den Daten nach markanten Mustern, die den Eintritt in den Flow, Flow selbst und den Austritt aus dem Flow markieren.

# Methode 
## Untersuchungsdesign 

Ein männlicher Freizeitläufer (29) nahm am Experiment teil. Er lief in sechs aufeinanderfolgenden Wochen an einem Tag 60 Minuten jeweils die gleiche Strecke und zur gleichen Tageszeit.

Vor jedem Lauf rüstete ich ihn mit einem geladenen Smartphone, einem passenden Smartphone-Armband, zwei geladenen Bewegungssensoren, einem geladenen Elektrokardiogramm (EKG)-Sensoren und vier Elektroden aus. Die Anordnung des Equipments ist Abbildung 1 zu entnehmen.

![Anordnung des Equipments](./figures/equipment-arrangement.png)

Abbildung 1: Anordnung des Equipments

Während jedes Laufes nutzte ich die dafür eigens entwickelte mobile Datenaufnahme App, um EKG und Bewegungsdaten mit Hilfe der tragbaren Sensoren des Unternehmens Shimmer Research (Shimmer 2r) aufzuzeichnen. Die Datenaufnahme App läuft auf dem Android OS ab Version 4.4 und kommuniziert mit den Sensoren über Bluetooth. Die Bewegungssensoren besitzen einen Beschleunigungsmesser und ein Kreiselinstrument, die beide auf jeweils drei Achsen messen. Für das Experiment nutzte ich das Smartphone Samsung Galaxy Nexus, welches auch über einen Beschleunigungsmesser und ein Kreiselinstrument verfügt. Alle Bewegungssensoren arbeiten mit einer Datenrate von 100 Hz. Der EKG-Sensor von Shimmer Research arbeitet mit vier Ableitungen. Im Experiment nutzte ich Knopfelektroden und eine Datenrate von 204.8 Hz. Alle 15 Minuten während jedes Laufes forderte die Datenaufnahme App mit einem Signal den Läufer auf, eine FSK auszufüllen. Vor jedem Lauf führte der Läufer eine 15-minütige Baseline Messung durch. 

Nach jedem Lauf übertrug ich die gesammelten Daten für die software-technische Analyse auf meinen Arbeitsrechner. Die Daten bestehen für jeden Lauf aus kontinuierlichen EKG-Daten, Global Positioning System (GPS)-Positionen, Beschleunigungen und Winkelgeschwindigkeiten von den Körperpositionen Bein, Arm und Handgelenk. 

## Flow-Diagnostik
### Datenverarbeitung

#### Flow-Kurzskala

Zur subjektiven Erfassung des Flow-Erlebens kam die Flow-Kurzskala (FKS) von **Rheinberg, Vollmeyer und Engeser (2003)** zum Einsatz. Die FKS besteht aus insgesamt 16 Items. Die ersten 10 Items bilden anhand einer 7-Punkte-Likert-Skala ("trifft nicht zu" = 1 bis "trifft zu" = 7) Komponenten des Flow-Erlebens ab und man fasst sie als Generalfaktor zusammen. Zur weiteren Differenzierung des Flow-Konstrukts ist der Generalfaktor der FKS in zwei Faktoren (Subdimensionen) unterteilt worden. Faktor I umfasst dabei sechs Items, die durchweg Aussagen zum "Glatten automatisierten Verlauf" einer Handlung beschreiben. Faktor II beinhaltet vier Items, die mit "Absorbiertheit" in Zusammenhang stehen. Der Reliabilitätskoeffizient der 10 Items im Generalfaktor (Cronbachs Alpha) liegt nach Angaben **Rheinbergs (2003)** im Bereich um $\alpha = 0.90$. Da nicht damit zu rechnen ist, dass in Anforderungssituationen ausschließlich Flow entsteht, sondern auch Angst und Besorgnis ausgelöst werden kann, wurde die FKS durch eine "Besorgniskomponente" erweitert. Diese besteht aus drei Items (Nr. 11 bis 13, Cronbachs $\alpha = 0.80$ bis $\alpha = 0.90$). Am Ende der FKS nehmen die Probanden noch drei Einschätzungen zur Anforderungs-Fähigkeits-Passung (AFP) (auf einer 9-Punkte-Skala) vor. Dabei fokussiert das Item 14 auf einen Vergleich der Schwierigkeit der jetzigen Tätigkeit mit allen anderen Tätigkeiten (leicht vs. schwer) und das Item 15 auf die eigene Leistungsfähigkeit (niedrig vs. hoch). Das Item 16 fragt direkt, auf die aktuelle Tätigkeit (hier also dem Laufabchnitt) bezogen, nach der subjektiv wahrgenommenen AFP (zu gering vs. zu hoch). In Tabelle 1 sind die Ergebnisse der Flow-Skalen des Laufes vom Donnerstag, den 31. Oktober 2013 dargestellt. In diesem Lauf steigt die AFP kontinuirlich und am Ende erzielt der Läufer seinen höchsten Flow-Gesamtwert. 

```{r calculate-fss-features, echo=FALSE, message=FALSE, warning=FALSE}
  library("flow")
  
  # Set start time
  start.time <- as.POSIXct(strptime("2013-10-31 18:11:26", "%Y-%m-%d %H:%M:%S"), tz="CET")
  
  # Set file path
  file.path <- paste("/Users/simonbogutzky/Entwicklung/bogutzky/repositories/non-disruptive-flow-measures/data/", format(start.time, format="%Y-%m-%d--%H-%M-%S", tz="CET"), "/", sep="")
  
  # Load fss data
  fss.data  <- read.csv(paste(file.path, "fss-data.csv", sep=""), header=T)
  
  # Calculate fss features
  fss.features.list <- c()
  for(i in 1:nrow(fss.data)) {
      fss.features.list <- c(fss.features.list, CalculateFlowShortScaleResults(c(t(fss.data[i, 1:16])), start=as.POSIXct(fss.data[i, 17]/1000, origin="1970-01-01", tz="CET"), end=as.POSIXct(fss.data[i, 18]/1000, origin="1970-01-01", tz="CET")))
  }

    # Extract flow features
  flow        <- c(fss.features.list[1][[1]][[1]][[1]], fss.features.list[2][[1]][[1]][[1]], fss.features.list[3][[1]][[1]][[1]], fss.features.list[4][[1]][[1]][[1]], fss.features.list[5][[1]][[1]][[1]])
  fluency     <- c(fss.features.list[1][[1]][[1]][[2]], fss.features.list[2][[1]][[1]][[2]], fss.features.list[3][[1]][[1]][[2]], fss.features.list[4][[1]][[1]][[2]], fss.features.list[5][[1]][[1]][[2]])
  absorption  <- c(fss.features.list[1][[1]][[1]][[3]], fss.features.list[2][[1]][[1]][[3]], fss.features.list[3][[1]][[1]][[3]], fss.features.list[4][[1]][[1]][[3]], fss.features.list[5][[1]][[1]][[3]])
  anxiety     <- c(fss.features.list[1][[1]][[1]][[4]], fss.features.list[2][[1]][[1]][[4]], fss.features.list[3][[1]][[1]][[4]], fss.features.list[4][[1]][[1]][[4]], fss.features.list[5][[1]][[1]][[4]])
  fit         <- c(fss.features.list[1][[1]][[1]][[5]], fss.features.list[2][[1]][[1]][[5]], fss.features.list[3][[1]][[1]][[5]], fss.features.list[4][[1]][[1]][[5]], fss.features.list[5][[1]][[1]][[5]])
  fss.features  <- data.frame(flow, fluency, absorption, anxiety, fit)

# Clean up
rm(fss.data, flow, fluency, absorption, anxiety, fit)
```

| Faktoren        | Nach Baseline |  Nach 15 Min. |  Nach 30 Min. |  Nach 45 Min. |  Nach 60 Min. |
|-----------------|--------------:|--------------:|--------------:|--------------:|--------------:|
|                 | M (SD)        | M (SD)        | M (SD)        | M (SD)        | M (SD)        |
|-----------------|---------------|---------------|---------------|---------------|---------------|
| Generalfaktor   | `r format(round(fss.features.list[1][[1]][[1]][[1]], 2), nsmall=2)` (`r format(round(fss.features.list[1][[1]][[2]][[1]], 2), nsmall=2)`) | `r format(round(fss.features.list[2][[1]][[1]][[1]], 2), nsmall=2)` (`r format(round(fss.features.list[1][[1]][[2]][[1]], 2), nsmall=2)`) | `r format(round(fss.features.list[3][[1]][[1]][[1]], 2), nsmall=2)` (`r format(round(fss.features.list[3][[1]][[2]][[1]], 2), nsmall=2)`) | `r format(round(fss.features.list[4][[1]][[1]][[1]], 2), nsmall=2)` (`r format(round(fss.features.list[4][[1]][[2]][[1]], 2), nsmall=2)`) | `r format(round(fss.features.list[5][[1]][[1]][[1]], 2), nsmall=2)` (`r format(round(fss.features.list[5][[1]][[2]][[1]], 2), nsmall=2)`) |
| Glatter Verlauf | `r format(round(fss.features.list[1][[1]][[1]][[2]], 2), nsmall=2)` (`r format(round(fss.features.list[1][[1]][[2]][[2]], 2), nsmall=2)`) | `r format(round(fss.features.list[2][[1]][[1]][[2]], 2), nsmall=2)` (`r format(round(fss.features.list[2][[1]][[2]][[2]], 2), nsmall=2)`) | `r format(round(fss.features.list[3][[1]][[1]][[2]], 2), nsmall=2)` (`r format(round(fss.features.list[3][[1]][[2]][[2]], 2), nsmall=2)`) | `r format(round(fss.features.list[4][[1]][[1]][[2]], 2), nsmall=2)` (`r format(round(fss.features.list[4][[1]][[2]][[2]], 2), nsmall=2)`) | `r format(round(fss.features.list[5][[1]][[1]][[2]], 2), nsmall=2)` (`r format(round(fss.features.list[5][[1]][[2]][[2]], 2), nsmall=2)`) |
| Absorbiertheit  | `r format(round(fss.features.list[1][[1]][[1]][[3]], 2), nsmall=2)` (`r format(round(fss.features.list[1][[1]][[2]][[3]], 2), nsmall=2)`) | `r format(round(fss.features.list[2][[1]][[1]][[3]], 2), nsmall=2)` (`r format(round(fss.features.list[2][[1]][[2]][[3]], 2), nsmall=2)`) | `r format(round(fss.features.list[3][[1]][[1]][[3]], 2), nsmall=2)` (`r format(round(fss.features.list[3][[1]][[2]][[3]], 2), nsmall=2)`) | `r format(round(fss.features.list[4][[1]][[1]][[3]], 2), nsmall=2)` (`r format(round(fss.features.list[4][[1]][[2]][[3]], 2), nsmall=2)`) | `r format(round(fss.features.list[5][[1]][[1]][[3]], 2), nsmall=2)` (`r format(round(fss.features.list[5][[1]][[2]][[3]], 2), nsmall=2)`) |
| Besorgnis       | `r format(round(fss.features.list[1][[1]][[1]][[4]], 2), nsmall=2)` (`r format(round(fss.features.list[1][[1]][[2]][[4]], 2), nsmall=2)`) | `r format(round(fss.features.list[2][[1]][[1]][[4]], 2), nsmall=2)` (`r format(round(fss.features.list[2][[1]][[2]][[4]], 2), nsmall=2)`) | `r format(round(fss.features.list[3][[1]][[1]][[4]], 2), nsmall=2)` (`r format(round(fss.features.list[3][[1]][[2]][[4]], 2), nsmall=2)`) | `r format(round(fss.features.list[4][[1]][[1]][[4]], 2), nsmall=2)` (`r format(round(fss.features.list[4][[1]][[2]][[4]], 2), nsmall=2)`) | `r format(round(fss.features.list[5][[1]][[1]][[4]], 2), nsmall=2)` (`r format(round(fss.features.list[5][[1]][[2]][[4]], 2), nsmall=2)`) |
| AFP             | `r format(round(fss.features.list[1][[1]][[1]][[5]], 2), nsmall=2)` (`r format(round(fss.features.list[1][[1]][[2]][[5]], 2), nsmall=2)`) | `r format(round(fss.features.list[2][[1]][[1]][[5]], 2), nsmall=2)` (`r format(round(fss.features.list[2][[1]][[2]][[5]], 2), nsmall=2)`) | `r format(round(fss.features.list[3][[1]][[1]][[5]], 2), nsmall=2)` (`r format(round(fss.features.list[3][[1]][[2]][[5]], 2), nsmall=2)`) | `r format(round(fss.features.list[4][[1]][[1]][[5]], 2), nsmall=2)` (`r format(round(fss.features.list[4][[1]][[2]][[5]], 2), nsmall=2)`) | `r format(round(fss.features.list[5][[1]][[1]][[5]], 2), nsmall=2)` (`r format(round(fss.features.list[5][[1]][[2]][[5]], 2), nsmall=2)`) |

Table: Ergebnisse vom `r strftime(start.time, format = "%A, den %d. %B %Y")`

Als Maßzahl nutze ich die zweite Subdimension der Flow-Kurzskala wie **Peifer (2014)**, da Absorbiertheit laut **Rheinberg & Vollmeyer (2003)** nur eintritt, wenn Anforderungen und Fähigkeiten sich in Balance befinden — somit ist sie ausschließlich im *Flow-Kanal* anzutreffen und deshalb ein repräsentativer Indikator für Flow als der Generalfaktor, der sich aus den zwei Subdimension zusammensetzt. Denn einen glatten Verlauf kann man auch auf Unterforderung zurückführen. Exemplarisch wird der Verlauf der Absorbiertheit in Abbildung 2 dargestellt.

```{r figure-02, eval=TRUE, echo=FALSE, fig.width=6.5, dev=c('postscript', 'tiff'), dpi=800, warning=FALSE}
  par(mfcol=c(1, 1), mar=c(2.5, 3.5, 1.5, 3.5) + 0.1, mgp=c(2.5, .5, 0), las=1, cex.axis=0.8, tck=.01, cex.lab=.8)
  
  # Set data
  x <- c(fss.features.list[2][[1]][[3]][[1]], fss.features.list[3][[1]][[3]][[1]], fss.features.list[4][[1]][[3]][[1]], fss.features.list[5][[1]][[3]][[1]])
  y <- c(fss.features.list[2][[1]][[1]][[3]], fss.features.list[3][[1]][[1]][[3]], fss.features.list[4][[1]][[1]][[3]], fss.features.list[5][[1]][[1]][[3]])

  # Plot data
  plot(x, y, type="b", xlab ="Zeit", ylab="Absorbiertheit", pch=21, ylim=c(3, 6), xaxt="n", yaxt="n")

  # Plot ticks
  axis(1, at=x, label=format(x, "%H:%M:%S"))
  axis(2, at=seq(3, 6, .25), labels=seq(3, 6, .25))
  axis(3, at=x, label=rep("", length(x)))
  axis(4, at=seq(3, 6, .25), labels=rep("", length(seq(3, 6, .25))))

  # Plot box again
  box()

  # Clean up
  rm(x, y)
```
Abbildung 2: Bewertete Absorbiertheit nach jeweils 15 Minuten Laufen

#### HRV-Analyse
Von den EKG-Daten entfernte ich die Zeiten für die Befragung und erhielt jeweils 15-Minuten Abschnitte. Diese 15-Minuten Abschnitte las ich in Kubios HRV (Version 2.1) ein. Kubios HRV automatische R-Spitzen-Erkennung erkennt die meisten Herzschläge. Trotzdem ist eine manuelle Nachbearbeitung notwendig. Nicht erkannte Herzschläge fügte ich hinzu und zuviel erkannte Herzschläge entfernte ich. 

```{r subset-ecg-data, echo=FALSE, message=FALSE, warning=FALSE}

  # Load ecg data 
  ecg.data  <- read.csv(paste(file.path, "/ecg-data.csv", sep=""), header=T)
  
  # Set function attributes
  starts    <- c(start.time, fss.features.list[1][[1]][[3]][[2]], fss.features.list[2][[1]][[3]][[2]], fss.features.list[3][[1]][[3]][[2]], fss.features.list[4][[1]][[3]][[2]])
  ends      <- c(fss.features.list[1][[1]][[3]][[1]], fss.features.list[2][[1]][[3]][[1]], fss.features.list[3][[1]][[3]][[1]], fss.features.list[4][[1]][[3]][[1]], fss.features.list[5][[1]][[3]][[1]])
  times     <- as.POSIXct(ecg.data[, 4]/1000, origin="1970-01-01", tz="CET")
  file.name <- "ecg-data"
  
  # Write subset in csv files
  WriteDataSubsetInCSVFile(ecg.data, times, starts, ends, file.name=file.name, file.path=file.path)
  
  # Clean up
  rm(file.name)
```

```{r calculate-hrv-features, echo=FALSE, message=FALSE, warning=FALSE}
  library(RHRV)
  
  # Create feature vector
  hrv.features <- c() 

  for (j in 1:i) {
    
    # Set hrv file name
    hrv.file.name <- paste(file.path, "ecg-data-", j, "_hrv.txt", sep="")
    if(file.exists(hrv.file.name)) {
      
        # Load Kubios HRV txt data
        hrv.kubios.data   <- read.csv(hrv.file.name, header = F, na.strings = "", fill = T, skip = 97, col.names = c("NA1", "Time", "RRInterval", "FFTFrequency", "FFTPSD", "ARFrequency", "ARPSD", "NA2", "NA3", "NA4", "NA5"))
        
        # Get time and rr-intervals
        time              <- hrv.kubios.data$Time
        time              <- time[complete.cases(time)]
        rr.interval       <- hrv.kubios.data$RRInterval
        rr.interval       <- rr.interval[complete.cases(rr.interval)]
        
        # Create hrv data of 10 minutes of the end of the whole data
        hrv.data          <- CreateHRVData()
        hrv.data          <- SetVerbose(hrv.data, FALSE)
        hrv.data$Beat     <- data.frame("Time"=time[time >= time[length(time)] - 60 * 10])
        
        # Build not interpolated heart rates
        hrv.data          <- BuildNIHR(hrv.data)
        #PlotNIHR(hrv.data)
        
        # Remove artefact manually
        #hrv.data          <- EditNIHR(hrv.data)
        #PlotNIHR(hrv.data)
        
        # Filter niHR
        s                 <- sd(hrv.data$Beat$niHR)
        m                 <- mean(hrv.data$Beat$niHR)
        minbpm            <- m - 3 * s
        maxbpm            <- m + 3 * s
        hrv.data          <-  FilterNIHR(hrv.data, long=50, last=13, minbpm=minbpm, maxbpm=maxbpm)
        #PlotNIHR(hrv.data)
        
        # Linear Interpolate the data by 4 Hz (default)
        hrv.data          <- InterpolateNIHR(hrv.data)
        #PlotHR(hrv.data)
        
        # Create time analysis
        #hrv.data          <- CreateTimeAnalysis(hrv.data, size=60)
        
        # Plot spectogram with Short-time Fourier transform 30 seconds window with 1 second shift for LF
        #PlotSpectrogram(hrv.data, size=30, shift=1, freqRange=c(0.04, 0.15))
        
        # Plot spectogram with Short-time Fourier transform 30 seconds window with 1 second shift for HF-VHF
        #PlotSpectrogram(hrv.data, size=10, shift=1, freqRange=c(0.15, 1))
        
        # Create Frequency analysis (CWT) with least asymmetric Daubechies of width 8 for ULF, VLF, LF and (HF + VHF) as HF 
        hrv.data          <- CreateFreqAnalysis(hrv.data)
        hrv.data          <- CalculatePowerBand(hrv.data, indexFreqAnalysis=1, type="wavelet", wavelet="la8", bandtolerance=0.005, ULFmin=0, ULFmax=0.0033, VLFmin=0.0033, VLFmax=0.04, LFmin=0.04, LFmax=0.15, HFmin=0.15, HFmax= 1)
        
        # Plot bands
        #PlotPowerBand(hrv.data, indexFreqAnalysis=1, hr=TRUE)
        
        # Calculate HRV features
        ulf.power.a       <- mean(hrv.data$FreqAnalysis[[1]]$ULF)
        vlf.power.a       <- mean(hrv.data$FreqAnalysis[[1]]$VLF)
        lf.power.a        <- mean(hrv.data$FreqAnalysis[[1]]$LF)
        hf.power.a        <- mean(hrv.data$FreqAnalysis[[1]]$HF)
        total.power       <- ulf.power.a + vlf.power.a + lf.power.a + hf.power.a
        ulf.power.r       <- ulf.power.a/total.power * 100
        vlf.power.r       <- vlf.power.a/total.power * 100
        lf.power.r        <- lf.power.a/total.power * 100
        hf.power.r        <- hf.power.a/total.power * 100
        lf.power.nu       <- lf.power.a/(lf.power.a + hf.power.a) * 100
        hf.power.nu       <- hf.power.a/(lf.power.a + hf.power.a) * 100
        lfhf              <- lf.power.a/hf.power.a
        mean.hr           <- mean(hrv.data$HR)
        
        # Add features to feature vector
        hrv.features      <- c(hrv.features, lf.power.a, hf.power.a, lf.power.r, hf.power.r, lf.power.nu, hf.power.nu, lfhf, total.power, mean.hr)
        
        # Clean up
        rm(ulf.power.a, vlf.power.a, lf.power.a, hf.power.a, total.power, ulf.power.r, vlf.power.r, lf.power.r, hf.power.r, lf.power.nu, hf.power.nu, lfhf, mean.hr)
      }
  }
  
  # Make data frame
  dimnames      <- list(row=c("lf.power.a", "hf.power.a", "lf.power.r", "hf.power.r", "lf.power.nu", "hf.power.nu", "lfhf", "total.power", "mean.hr"), col=1:i)
  hrv.features  <- as.data.frame(t(matrix(hrv.features, ncol=i, nrow=9, dimnames=dimnames)))

  # Clean up
  rm(j, s, m, minbpm, maxbpm, hrv.kubios.data, dimnames)
```

- Warum nur 10 Minunten?
Wegen der Erholung am Anfang des Laufes und der Erholung nach den Befragungen (verweiß auf das Bild)

- Wie wurde Interpoliert? - 4 Hz

Prior to spectrum estimation, the RR interval series is converted to equidistantly sampled series by linear interpolation. (Tarvainen2014)

- Wie wurde weiter gefiltert?

This function implements an algorithm that uses adaptive thresholds for rejecting or accepting beats [33]. The rule for beat acceptation or rejection is to compare the present beat with the previous one, the following one and with an updated mean of the RR interval. The different adaptive thresholds establish an upper limit for the relative errors of each of these comparisons. The long parameter allows the user to specify the number of beats that shall be used to calculate the updated mean (default value is 50 heartbeats). Also, the last parameter permits the user to specify the initial threshold value in % (default value is 13%). Finally, the algorithm also applies a comparison with acceptable physiological values. The user can specify the range of acceptable physiological values by using the minbpm and maxbpm (minimum beats per minute and maximum beats per minute, respectively). (RHRV Tutorial)

Drop beats and N-N intervals deviating more than three standard
deviations deviations from the mean interval were excluded and replaced with values calculated by linear interpolation between adjacent normal N-N intervals, using a custom made script in MATLAB. (DeManzano2010)

- Warum wurde die Wavelet Transformation und die gewählten Bandbreiten gewählt?

Einige Autoren argumentieren, dass für hohe lntensitäten (> 70 % V02max) die Tauglichkeit der traditionellen Spektralanalyse der HRV im allgemeinen und insbesondere der absoluten Einheiten zur Beschreibung der autonomen Funktion unter Belastung kaum geeignet ist (Tulppo et al. , 1996; Warren et al., 1997; Cottin et al., 1999; Hautala et al. , 2003; Pichon et al., 2004; Sandercock & Brodie, 2006). Dies wird einerseits mit methodischen Problemen wie der belastungsbedingten Nichtstationarität und dem niedrigen SNR und andererseits mit den inkonsistenten, nicht zu den physiologischen Vorgängen der belastungsinduzierten Verschiebung von der vagalen zur sympathikotonen Dominanz passenden HRV-Ergebnissen. Daraus wird allerdings in jüngsten Arbeiten keine Abkehr von HRV-Untersuchungen unter Belastung abgeleitet, sondern viel mehr ein methodisches und inhaltliches Umdenken (u. a. Anosov et al. , 2000; Hautala et al., 2003; Blain et al., 2005b; Blain et al., 2005a; Cottin et al. , 2006; Cottin et al., 2007a; Casties et al., 2006; Sandercock & Brodie, 2006; Lewis et al., 2007). Die genannten Arbeitsgruppen weisen dabei explizit auf den in diesem Zusammenhang deutlich adäquateren Methodeneinsatz alternativer Spektralanalysemethoden (z. B. Coarse Graining Spektralanalyse (CGSA), Kurzzeitfourier-Analyse (STFT) oder kontinuierliche Wavelet-transformation (CWT)) oder nicht-linearer Verfahren (insb. Detrended Fluctuation Analysis (DFA), Sampie Entropie (SampEn)) hin und fordern bei Verwendung von ersteren eine belastungsadäquate Erweiterung des HF-Spektralbands mindestens bis zur maximalen Atemfrequenz (-1 Hz). Des Weiteren wird eine Abkehr von der rein neuro-vegetativen, sympathiko-vagalen Interpretation der Spektralbänder gefordert, da sich im HF-Band bei sportlicher Belastung vor allem mechanisch bedingte Resonanz- und Kopplungsphänomene mit der Atmung und der motorischen Aktivität zu manifestieren scheinen (u. a. Blain et al., 2005b; Meste et al., 2005; Casties et al., 2006; Meste et al., 2007; Blain et al., 2009)4. (Hoos2010)

A basic problem in HRV analysis is non-stationarity of the heart rate signal, which holds
particularly true for exercise conditions. Standard spectral HRV analysis (i.e., FFT) should not be applied to exercise conditions. The use of WTs analyses shows much promise in this area. The use ofWT allows for the detailed assessment of the evolution of the cardiac response enabling us to individually establish the moments in which the organism establishes functional modifications in order to respond to the impact of the intensity load. With wavelet transforms, changes in HRV signal of energy (total, LF, and HF-VHF) and
the evolution of peaks of the two assessed bands (LFpeak and HF-VHFpeak)may be used for instantaneous and continuous control of the organism's functional response, enabling us to
detect minimal adaptive changes in the organism as a response to exercises of different intensity and duration. It can be stated, overall, that the relative weight (%) of the two frequency bands (LF and HF-VHF) varied with regards to exercise in proportion to the intensity of the effort and the duration of the test. Despite the continuous decrease in total power spectral density, the greater weight of variability was always observed in the LF band. With fatigue, however, the relative weight (%) of HF-VHF increased, while that of LF fell, thus modifying the LF/HF ratio. (Sarmiento2013)

The wavelet transform is a powerful tool for analyzing non-stationary signals, such as the RR time series. The analysis is based on the mother wavelet, a well- localized, oscillating, regular function ψ(t). Mother wavelets functions, unlike the sinusoidal functions on which Fourier transform is based, are localized in space. This endows theWavelet transform with both temporal and spectral (scale) resolution,whichmakes it preferable to the Fourier transform for the analysis of non stationary signals. (Rodriguez-Linares2010)

- Wie wird die Wavelet Transformation ausgeführt?

Among the WPD transforms we have chosen the
Maximal Overlap Discrete Wavelet Packet Transform (MODWPT) (Percival and Walden, 2006) (Rodriguez-Linares2010)

The most used mother wavelets are available: Haar ("haar"),Daubechies ("d4", "d6", "d8" and "d16") and the least asymmetric("la8", "la16" and "la20"), among others. The default mother wavelet is "d4" (Daubechies, 2006).WhenWavelet analysis is used in the CalculatePowerBand() function, a tolerance for the bands' boundaries is requiered for the power spectrum calculations. This tolerance is is specified with the parameter bandtolerance, which takes a default value of 0.01. (Rodriguez-Linares2010)

For example, "la8" belongs to the Least Asymmetric family and has a length of 8 samples. We may give a simple advice for wavelet selection based on the wavelet's length: shorter wavelets usually have better temporal resolution, but worse frequency resolution. On the other hand, longer wavelets usually have worse temporal resolution, but they provide better frequency resolution. Better temporal resolution means that we can study shorter time intervals. We may select the least asymmetric Daubechies of width 8 ("la8") as wavelet, since it provides a good compromise between frequency and time resolution. (RHRV Tutorial)


Warum LF und HF?

One particular approach to analyze HRV is to use spectral methods that provide information about how variance in HR ("power") distributes as a function of frequency (Task Force Guidelines, 1996). One of the relevant parameters in spectral analyses is the high-frequency component of the heart rate variability (HF-HRV), which reflects variance in the high frequency range (0.15-0.4 Hz). HF-HRV has been shown to be a reliable indicator for parasympathetic efferent activity (Porges, 1995) and increased task demands are related to a low level of HF-HRV (Backs et al., 1991; Mulder et al., 2002). Furthermore, increased HF-HRV is associated with efficient use of strategies for self-regulation and attention, which results in better performance in cognitive tasks (better accuracy and shorter reaction time) (Hansen et al, 2003; Thayer et al., 2009). In contrast, decreased HF-HRV is related to limited use of self-regulatory strategies (Thayer & Brosschot, 2005), for example, failure to recognize task relevant information or to habituate to novel, non-relevant stimuli (hypervigilance; Friedman, 2007; Thayer, Friedman, Borkovec, Johnsen, & Molina, 2000; Thayer et al., 2009). Focusing on task relevant stimuli and fading out task-irrelevant information are key components of flow. Therefore, one can assume a positive relation between flow and HF-HRV. However, prior studies suggest that moderate and increased task demands are related to lower levels of HF-HRV (Backs et al., 1991; Jorna, 1992; Mulder et al., 2002 Vicente et al., 1987). Based on these findings, we hypothesize a relation between flow and HF-HRV without making any assumptions regarding the direction of the relationship. Another parameter of HRV is the low-frequency component of the HRV (LF-HRV), which reflects the variance in the low frequency range (0.04-0.15 Hz) of heart rates. The meaning of this parameter is controversial in recent research. LF-HRV has been used as an indicator for sympathetic activity (Pagani et al., 1986; Malliani, Pagani, Lombardi, & Cerutti, 1991). However, a growing body of research disproved this assumption and showed that LF-HRV rather reflects baroreflex modulation (Heathers, 2014; Rahman, Pechnik, Gross, Sewall, Goldstein, 2011; Schroeder et al., 2003). The baroreflex is one of the elementary mechanisms through which acute changes in the heart rate and blood pressure is controlled (Guyton, 1980) Baroreflex activity has been associated with several cognitive functions such as mental stress (del Paso, Langewitz, Robles, & Pérez, 1996; Robbe et al., 1987, Steptoe & Sawada, 1989), cognitive-attentional demands (del Paso, González, & Hernández, 2004), and cognitive performance (Yasumasu, del Paso, Takahara, & Nakashima, 2006). According to Lacey's intake/rejection hypothesis (Lacey & Lacey, 1970), tasks containing cognitive elaboration are related to a baroreceptor-elicited cardiac acceleration (del Paso et al., 2004). In contrast, activities involving the detection of external stimuli are related to a baroreceptor-modulated cardiac deceleration (Bernardi, Porta, Spicuzza, & Sleight, 2005). Yasumasu et al. (2006) showed that activities that involve cognitive elaboration and rejection of external stimuli cause a decrease of baroreflex activity, which in turn causes an increase in cardiovascular activity (i.e., increase in heart rate). Cognitive involvement in an activity and rejection of external stimuli are crucial for experiencing flow. Furthermore, previous research suggests an inverted u-shaped function between flow and LF-HRV (Peifer et al., 2014b). Based on these results, we assume a relation between LF-HRV (as an indicator for baroreflex function) and flow experience and test this assumption in an experimental setting that addresses the aforementioned limitations of previous studies. (Tozman2015)

```{r figure-03, eval=TRUE, echo=FALSE, fig.width=6.5, dev=c('tiff'), dpi=800, warning=FALSE}
  par(mfcol=c(4, 1), mar=c(3, 3, 1.5, 3) + 0.1, mgp=c(2, .5, 0), las=1, cex.axis=0.8, tck=.01, cex.lab=.8, xaxs="i", yaxs="i")
  
  # Set data
  t     <- ecg.data[, 1]
  y     <- ecg.data[, 3]
  end   <- ends[length(ends)]
  start <- starts[length(starts)]
  
  # Plot all ecg data
  plot(t, y, type="l", xlab="", ylab=expression("EKG LA LL ["~mV~"]"), xaxt="n", yaxt="n", col="darkgrey")
  par(new = T)
  plot(times, y, type="n", xlab="", ylab="", xaxt="n", yaxt="n")

  # Mark interesting part
  polygon(c(start, start, end, end), c(-6, 6, 6, -6), col = rgb(1, 1, 0, .1), border = rgb(0, 0, 0, 0))
  
  # Plot ticks and vertical lines
  axis(1, at=c(starts, ends), label=format(c(starts, ends), "%H:%M:%S"))
  axis(2, at=seq(-6, 6, 2), labels=seq(-6, 6, 2))
  axis(3, at=c(starts, ends), label=rep("", length(c(starts, ends))))
  axis(4, at=seq(-6, 6, 2), labels=rep("", length(seq(-6, 6, 2))))
  abline(v=starts, lty="dashed")
  abline(v=ends, lty="dashed")
  
  # Plot box again
  box()
  
  # Add reference letter  
  mtext("A", 4, line=2)

  # Plot the last 15 minutes of ecg data
  isIn         <- start - 30 <= times & end + 30 >= times
  t            <- t[isIn]
  y            <- y[isIn]
  times.subset <- times[isIn]
  
  plot(t, y, type="l", xlab="", ylab=expression("EKG LA LL ["~mV~"]"), xaxt="n", yaxt="n", col="darkgrey")
  par(new = T)
  plot(times.subset, y, type="n", xlab="", ylab="", xaxt="n", yaxt="n")

  # Plot ticks and vertical lines
  axis(1, at=c(starts, ends), label=format(c(starts, ends), "%H:%M:%S"))
  axis(2, at=seq(-6, 6, 2), labels=seq(-6, 6, 2))
  axis(3, at=c(starts, ends), label=rep("", length(c(starts, ends))))
  axis(4, at=seq(-6, 6, 2), labels=rep("", length(seq(-6, 6, 2))))
  abline(v=starts, lty="dashed")
  abline(v=ends, lty="dashed")

  # Plot box again
  box()

  # Add reference letter  
  mtext("B", 4, line=2)

  # Set data
  t         <- time
  y         <- rr.interval
  end.rr    <- max(t)
  start.rr  <- min(t)
  xlim      <- c(start.rr - 30, end.rr + 30)
  
  # Plot rrIntervals
  plot(t, y, type="l", xlab="", ylab=expression("RR-Intervalle ["~s~"]"), xaxt="n", yaxt="n", xlim=xlim, col="darkgrey")

  # Mark interesting part
  polygon(c(end.rr - 10 * 60, end.rr - 10 * 60, end.rr, end.rr), c(0, 1, 1, -0), col = rgb(1, 1, 0, .1), border = rgb(0, 0, 0, 0))

  # Plot ticks and vertical lines
  marker <- c(start.rr, end.rr - 10 * 60, end.rr)
  axis(1, at=marker, label=format(c(start, end - 10 * 60, end), "%H:%M:%S"))
  axis(2, at=seq(.25, .50, .05), labels=seq(.25, .50, .05))
  axis(3, at=marker, label=rep("", length(marker)))
  axis(4, at=seq(.25, .50, .05), labels=rep("", length(seq(.25, .50, .05))))
  abline(v=marker, lty = "dashed")

  # Plot box again
  box()

  # Add reference letter  
  mtext("C", 4, line=2)

  # Set data
  t         <- hrv.data$Beat$Time
  y         <- hrv.data$Beat$RR / 1000
  end.rr    <- max(t)
  start.rr  <- min(t)
  xlim      <- c(start.rr - 30, end.rr + 30)
  
  # Plot rrIntervals
  plot(t, y, type="l", xlab="Zeit", ylab=expression("RR-Intervalle ["~s~"]"), xaxt="n", yaxt="n", xlim=xlim, col="darkgrey")

  # Plot ticks and vertical lines
  marker <- c(start.rr, end.rr)
  axis(1, at=marker, label=format(c(end - 10 * 60, end), "%H:%M:%S"))
  axis(2, at=seq(.25, .50, .025), labels=seq(.25, .50, .025))
  axis(3, at=marker, label=rep("", length(marker)))
  axis(4, at=seq(.25, .50, .025), labels=rep("", length(seq(.25, .50, .025))))
  abline(v=c(min(t), max(t)), lty = "dashed")

  # Plot box again
  box()

  # Add reference letter  
  mtext("D", 4, line=2)

  # Clean up
  rm(ecg.data, end, end.rr, hrv.data, isIn, marker, rr.interval, start, start.rr, t, time, times, times.subset, xlim, y)

```

| Parameter       | Nach Baseline |  Nach 15 Min. |  Nach 30 Min. |  Nach 45 Min. |  Nach 60 Min. |
|-----------------|--------------:|--------------:|--------------:|--------------:|--------------:|
| Mittlere Herzrate (BPM)  | `r format(round(hrv.features$mean.hr[1], 2), nsmall=2)` | `r format(round(hrv.features$mean.hr[2], 2), nsmall=2)` | `r format(round(hrv.features$mean.hr[3], 2), nsmall=2)` | `r format(round(hrv.features$mean.hr[4], 2), nsmall=2)` | `r format(round(hrv.features$mean.hr[5], 2), nsmall=2)` |
| LF (ms^2^)  | `r format(round(hrv.features$lf.power.a[1], 2), nsmall=2)` | `r format(round(hrv.features$lf.power.a[2], 2), nsmall=2)` | `r format(round(hrv.features$lf.power.a[3], 2), nsmall=2)` | `r format(round(hrv.features$lf.power.a[4], 2), nsmall=2)` | `r format(round(hrv.features$lf.power.a[5], 2), nsmall=2)` |
| HF-VHF (ms^2^)  | `r format(round(hrv.features$hf.power.a[1], 2), nsmall=2)` | `r format(round(hrv.features$hf.power.a[2], 2), nsmall=2)` | `r format(round(hrv.features$hf.power.a[3], 2), nsmall=2)` | `r format(round(hrv.features$hf.power.a[4], 2), nsmall=2)` | `r format(round(hrv.features$hf.power.a[5], 2), nsmall=2)` |
| Total (ms^2^)  | `r format(round(hrv.features$total.power[1], 2), nsmall=2)` | `r format(round(hrv.features$total.power[2], 2), nsmall=2)` | `r format(round(hrv.features$total.power[3], 2), nsmall=2)` | `r format(round(hrv.features$total.power[4], 2), nsmall=2)` | `r format(round(hrv.features$total.power[5], 2), nsmall=2)` |
| LF (%)  | `r format(round(hrv.features$lf.power.r[1], 2), nsmall=2)` | `r format(round(hrv.features$lf.power.r[2], 2), nsmall=2)` | `r format(round(hrv.features$lf.power.r[3], 2), nsmall=2)` | `r format(round(hrv.features$lf.power.r[4], 2), nsmall=2)` | `r format(round(hrv.features$lf.power.r[5], 2), nsmall=2)` |
| HF-VHF (%)  | `r format(round(hrv.features$hf.power.r[1], 2), nsmall=2)` | `r format(round(hrv.features$hf.power.r[2], 2), nsmall=2)` | `r format(round(hrv.features$hf.power.r[3], 2), nsmall=2)` | `r format(round(hrv.features$hf.power.r[4], 2), nsmall=2)` | `r format(round(hrv.features$hf.power.r[5], 2), nsmall=2)` |
| LF (n. u.)  | `r format(round(hrv.features$lf.power.nu[1], 2), nsmall=2)` | `r format(round(hrv.features$lf.power.nu[2], 2), nsmall=2)` | `r format(round(hrv.features$lf.power.nu[3], 2), nsmall=2)` | `r format(round(hrv.features$lf.power.nu[4], 2), nsmall=2)` | `r format(round(hrv.features$lf.power.nu[5], 2), nsmall=2)` |
| HF-VHF (n. u.)  | `r format(round(hrv.features$hf.power.nu[1], 2), nsmall=2)` | `r format(round(hrv.features$hf.power.nu[2], 2), nsmall=2)` | `r format(round(hrv.features$hf.power.nu[3], 2), nsmall=2)` | `r format(round(hrv.features$hf.power.nu[4], 2), nsmall=2)` | `r format(round(hrv.features$hf.power.nu[5], 2), nsmall=2)` |
| LF/HF-VHF  | `r format(round(hrv.features$lfhf[1], 2), nsmall=2)` | `r format(round(hrv.features$lfhf[2], 2), nsmall=2)` | `r format(round(hrv.features$lfhf[3], 2), nsmall=2)` | `r format(round(hrv.features$lfhf[4], 2), nsmall=2)` | `r format(round(hrv.features$lfhf[5], 2), nsmall=2)` |

Table: Ergebnisse vom `r strftime(start.time, format = "%A, den %d. %B %Y")`

```{r save-features, echo=FALSE, message=FALSE, warning=FALSE}
  
  # Append data
  if(file.exists("/Users/simonbogutzky/Entwicklung/bogutzky/repositories/non-disruptive-flow-measures/data/features.csv")) {
    features <- read.csv("/Users/simonbogutzky/Entwicklung/bogutzky/repositories/non-disruptive-flow-measures/data/features.csv")
    write.csv(rbind(features, cbind(fss.features, hrv.features)), "/Users/simonbogutzky/Entwicklung/bogutzky/repositories/non-disruptive-flow-measures/data/features.csv", row.names=FALSE)
  } else {
    write.csv(cbind(fss.features, hrv.features), "/Users/simonbogutzky/Entwicklung/bogutzky/repositories/non-disruptive-flow-measures/data/features.csv", row.names=FALSE)
  }
```

