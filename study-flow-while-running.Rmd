---
title: 'Studie: Flow beim Laufen'
author: "Simon Bogutzky"
date: "Mai 2015"
output:
  pdf_document:
    fig_caption: yes
    fig_crop: no
    highlight: null
    keep_tex: yes
header-includes: \usepackage[ngerman]{babel} \usepackage[printonlyused,withpage]{acronym}
  \usepackage{setspace} \usepackage{natbib} \usepackage{booktabs} \usepackage{dcolumn} \onehalfspacing \newcolumntype{x}{D{,}{\pm}{3.3}} \newcolumntype{y}{D{,}{\pm}{5.3}} \newcolumntype{z}{D{,}{\pm}{7.7}}
fontsize: 11pt
documentclass: scrartcl
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
  
  # Remove all variables
  rm(list = ls(all = T)) 

  # Set working directory
  setwd("~/Entwicklung/bogutzky/repositories/non-disruptive-flow-measures")

  # Load libraries
  library("flow")
  library("xtable")
  library(gplots)
  
  fss.features        <- read.csv("./data/features/fss-features.csv", stringsAsFactors = FALSE)
  fss.feature.subset <- fss.features
  fss.feature.subset[fss.feature.subset$activity == "Running",]$measurement <- fss.feature.subset[fss.feature.subset$activity == "Running",]$measurement + 1
  fss.feature.subset <- fss.feature.subset[,c(1:5, 7, 10)]
  fss.feature.subset <- fss.feature.subset[order(as.Date(fss.feature.subset$activity.start, format = "%Y-%m-%d %H:%M:%S")), , drop = FALSE]
  fss.feature.subset$measurement <- factor(fss.feature.subset$measurement, levels = c(1, 2, 3, 4, 5), labels = c("Ruhe", "15'", "30'", "45'", "60'"))

  hrv.features        <- read.csv("./data/features/hrv-features.csv", stringsAsFactors = FALSE)
  hrv.feature.subset <- hrv.features
  hrv.feature.subset[hrv.feature.subset$activity == "Running",]$measurement <- hrv.feature.subset[hrv.feature.subset$activity == "Running",]$measurement + 1
  hrv.feature.subset <- hrv.feature.subset[, c(1:9, 11, 15)]
  hrv.feature.subset <- hrv.feature.subset[order(as.Date(hrv.feature.subset$activity.start,format = "%Y-%m-%d %H:%M:%S")), , drop = FALSE]
  hrv.feature.subset$measurement <- factor(hrv.feature.subset$measurement, levels = c(1, 2, 3, 4, 5), labels = c("Ruhe", "15'", "30'", "45'", "60'"))
```

# Abkürzungsverzeichnis

\begin{acronym}[TDMA]
  \acro{AFP}{Anforderungs-Fähigkeits-Passung}
  \acro{ANS}{autonome Nervensystem}
	\acro{EKG}{Elektrokardiogramm}
	\acro{ESM}{Experience Sampling Method}
  \acro{FFT}{Fast Fourier Transformation}
	\acro{FKS}{Flow-Kurzskala}
	\acro{GPS}{Global Positioning System}
  \acro{HF}{High Frequency}
	\acro{HRV}{Herzfrequenzvariabilität}
  \acro{LF}{Low Frequency}
  \acro{VHF}{Very High Frequency}
  \acro{WT}{Wavelet Transformation}
\end{acronym}

# Ziel
Die Studie diente dazu statistische Beziehungen zwischen:

* Flow und der \ac{HRV}
<!-- * Flow und dem Bewegungsfluss -->

beim Laufen herzustellen. <!-- Des Weiteren suchte ich in den Daten nach markanten Mustern, die den Eintritt in den Flow, Flow selbst und den Austritt aus dem Flow markieren. -->

# Methode
## Flow-Diagnostik
### Flow-Kurzskala

Zur subjektiven Erfassung des Flow-Erlebens kam die \ac{FKS} von \citet{Rheinberg2003} zum Einsatz. Die \ac{FKS} besteht aus insgesamt 16 Items. Die ersten zehn Items bilden anhand einer 7-Punkte-Likert-Skala ("trifft nicht zu" = 1 bis "trifft zu" = 7) Komponenten des Flow-Erlebens ab und \citet{Rheinberg2003} fassen sie als Generalfaktor zusammen. Zur Differenzierung des Flow-Konstrukts ist der Generalfaktor der \ac{FKS} in zwei Faktoren (Subdimensionen) unterteilt. Faktor I umfasst sechs Items, die Aussagen zum "Glatten automatisierten Verlauf" einer Tätigkeit beschreiben. Faktor II beinhaltet vier Items, die mit "Absorbiertheit" in Zusammenhang stehen. Der Reliabilitätskoeffizient der zehn Items im Generalfaktor (Cronbachs Alpha) liegt nach Angaben von \citet[S. 9]{Rheinberg2003} im Bereich um $\alpha = 0.90$. Da nicht damit zu rechnen ist, dass in Anforderungssituationen ausschließlich Flow entsteht, sondern Anforderungssituationen auch Angst und Besorgnis auslösen können, erweiterten \citet{Rheinberg2003} die \ac{FKS} durch eine "Besorgniskomponente". Diese besteht aus drei Items (Nr. 11 bis 13, Cronbachs $\alpha = 0.80$ bis $\alpha = 0.90$). Am Ende der \ac{FKS} nehmen die Probanden drei Einschätzungen zur \ac{AFP} (auf einer 9-Punkte-Skala) vor. Das Item 14 fokussiert sich auf einen Vergleich der Schwierigkeit der jetzigen Tätigkeit mit allen anderen Tätigkeiten (leicht vs. schwer) und das Item 15 auf die eigene Leistungsfähigkeit (niedrig vs. hoch). Das Item 16 fragt direkt, auf die aktuelle Tätigkeit bezogen, nach der subjektiv wahrgenommenen \ac{AFP} (zu gering vs. zu hoch). 

### Herzfrequenzvariabilität
Die \ac{HRV} operationalisiert die Fluktuationen der Herzperiodendauer in einem festgelegten Zeitraum und wird aus der Zeitreihe der aufeinanderfolgenden RR-Intervalle mit Hilfe verschiedener Kenngrößen bestimmt \citep{TaskForce1996, Berntson1997}. Zwischen einzelnen Kenngrößen bzw. Merkmalen der \ac{HRV} und Flow-Erleben suche ich einen Zusammenhang.

## Untersuchungsdesign 
Ein männlicher Freizeitläufer (29) nahm am Experiment teil. Er lief in sechs aufeinanderfolgenden Wochen an einem Tag 60 Minuten jeweils die gleiche Strecke und zur gleichen Tageszeit.

Vor jedem Lauf rüstete ich ihn mit einem geladenen Smartphone, einem passenden Smartphone-Armband, zwei geladenen Bewegungssensoren, einem geladenen \ac{EKG}-Sensoren und vier Elektroden aus. Die Anordnung des Equipments ist Abbildung \ref{fig:anordnung-des-equipments} zu entnehmen.

\begin{figure}[htbp]
\centering
\includegraphics[keepaspectratio,width=0.75\textwidth]{./figures/equipment-arrangement.pdf}
\caption{Anordnung des Equipments — Smartphone am Oberarm; Bewegungssensoren am Handgelenk und Schienbein; EKG-Sensor mit vier Ableitungen am Oberkörper \label{fig:anordnung-des-equipments}}
\end{figure}

Während jedes Laufes zeichnete eine eigens entwickelte App \ac{EKG} und Bewegungsdaten mit Hilfe der tragbaren Sensoren des Unternehmens Shimmer Research (Shimmer 2r) auf. Die App läuft auf dem Android OS ab Version 4.4 und kommuniziert mit den Sensoren über Bluetooth. Die Bewegungssensoren besitzen einen Beschleunigungsmesser und ein Kreiselinstrument, die beide auf jeweils drei Achsen messen. Für das Experiment nutzte ich das Smartphone Samsung Galaxy Nexus, welches auch über einen Beschleunigungsmesser und ein Kreiselinstrument verfügt. Alle Bewegungssensoren arbeiten mit einer Datenrate von 100 Hz. Der \ac{EKG}-Sensor von Shimmer Research arbeitet mit vier Ableitungen. Im Experiment nutzte ich Knopfelektroden und eine Datenrate von 256 Hz. Alle 15 Minuten während jedes Laufes forderte die App mit einem Signal den Läufer auf, eine \ac{FKS} auszufüllen. Vor jedem Lauf führte der Läufer eine 15-minütige Ruhemessung durch. 

Nach jedem Lauf übertrug ich die gesammelten Daten für die software-technische Analyse auf meinen Arbeitsrechner. Die Daten bestehen für jeden Lauf aus der Bewertung der fünf \ac{FKS}, \ac{EKG}-Daten, \ac{GPS}-Positionen, Beschleunigungen und Winkelgeschwindigkeiten von den Körperpositionen Bein, Arm und Handgelenk. 

## Datenverarbeitung
### Flow-Kurzskala
Aus der Bewertung der \ac{FKS} berechnete ich die Faktoren der \ac{FKS}. Die Ergebnisse zeigt die Tabelle \ref{tab:fks-merkmale}. Der Generalfaktor steigt im arithmetischen Mittel von Ruhemessung zur ersten Laufmessung. Danach sinkt er ein wenig. Der glatte Verlauf fällt im arithmetischen Mittel bis zur 45-Minute. Danach steigt er ein wenig. Die Absorbiertheit verhält sich gegenläufig. Im arithmetischen Mitte steigt die \ac{AFP} kontinuierlich (siehe Abbildung \ref{fig:fks-faktoren}). 

```{r fks-merkmale, echo=FALSE, message=FALSE, warning=FALSE, results="asis"}
    
  # Create table
  options(stringsAsFactors = FALSE)
  feature.table           <- data.frame()
  for (i in 1:5) {
    feature.table <- rbind(feature.table, paste(formatC(round(tapply(fss.feature.subset[, i], fss.feature.subset[, 7], mean), 2), format = "f", digits = 2), ",", formatC(round(tapply(fss.feature.subset[, i], fss.feature.subset[, 7], sd), 2), format = "f", digits = 2)))
  }
  colnames(feature.table) <- levels(fss.feature.subset[, 7])
  rownames(feature.table) <- c("Generalfaktor", "glatter Verlauf", "Absorbiertheit", "Besorgnis", "AFP")
  
  # Print latex table
  table                   <- xtable(feature.table, label = "tab:fks-merkmale", align = "rxxxxx", caption = "Werte sind arithmetische Mittel ± Standardabweichung; Faktoren nach Ruhe, 15-, 30-, 45- und 60-Minuten Laufen [N = 6]") 
  print(table, caption.placement = "top", sanitize.rownames.function = function(x){x}, comment = FALSE, booktabs = TRUE)
  
  # Clean up
  rm(feature.table, table, i)
```

<!-- Zur Bewertung des subjektiven Flow-Zustands verwende ich die zweite Subdimension der \ac{FKS}. Denn die Absorbiertheit tritt laut \citet{Peifer2014} nur ein, wenn Anforderungen und Fähigkeiten sich in Balance befinden — somit ist sie ausschließlich im *Flow-Kanal* anzutreffen. Deshalb die Absorbiertheit ein repräsentativer Indikator für Flow als der Generalfaktor, der sich aus den zwei Subdimension zusammensetzt. Den Beleg hierfür geben \citet[S. 69]{Rheinberg2003a}. Sie stellten fest, dass Unterforderung keinen Einfluss auf den glatten Verlauf hat, jedoch die Absorbiertheit negativ beeinflusst. Auch im Vergleich von Ruhe- und Laufmessung (siehe Abbildung \ref{fig:absorbiertheit-afp-verlauf}) ist dieser Sachverhalt auszumachen. -->

```{r fks-faktoren, echo=FALSE, warning=FALSE, dev='pdf', fig.height=3, fig.width=6.5, fig.pos='htbp', fig.cap='Arithmetische Mittel von Absorbiertheit, AFP und glatten Verlauf nach Ruhe, 15-, 30-, 45- und 60-Minuten Laufen [N = 6] \\label{fig:fks-faktoren}'}
  par(mfcol=c(1, 1), mar=c(3.5, 3.5, 1.5, 3.5) + 0.1, mgp=c(2, .5, 0), las=1, cex.axis=0.8, tck=.01, cex.lab=.8, xaxs="r", yaxs="r")

  # Plot data
  plot(tapply(fss.feature.subset[, 1], fss.feature.subset[, 7], mean), type = "b", xlab = "Messung", ylab = "", pch = 21, bg = "#1D70B7", ylim = c(3, 6), xaxt = "n")
  lines(tapply(fss.feature.subset[, 2], fss.feature.subset[, 7], mean), type = "b", pch = 22, bg = "#1D70B7")
  lines(tapply(fss.feature.subset[, 3], fss.feature.subset[, 7], mean), type = "b", pch = 23, bg = "#1D70B7")
  lines(tapply(fss.feature.subset[, 5], fss.feature.subset[, 7], mean), type = "b", pch = 24, bg = "#1D70B7")

  # Plot ticks
  axis(1, at = 1:length(levels(fss.feature.subset$measurement)), label = levels(fss.feature.subset$measurement))
  axis(3, label = NA)
  axis(4, label = NA)

  legend("bottomright", inset=.05, c("Generalfaktor", "Glatter Verlauf", "Absorbiertheit", "AFP"), pch = c(21:24), pt.bg = "#1D70B7", cex = .7)

  # Plot box again
  box()
```

### HRV-Analyse
Von den \ac{EKG}-Daten entfernte ich die Zeiten für die Bewertung der \ac{FKS} und erhielt jeweils 15-Minuten Abschnitte (siehe Abbildung \ref{fig:ekg-signalverarbeitung} von A zu B). Zur effizienteren Verarbeitung in KubiosHRV \citep{Tarvainen2014} teilte ich die 15-Minuten Abschnitte in jeweils drei fünf Minuten Abschnitte (siehe Abbildung \ref{fig:ekg-signalverarbeitung} C). Zur RR-Intervall Berechnung las ich die 90 fünf Minuten Abschnitte in KubiosHRV (Version 2.1) ein. Die R-Spitzen-Erkennung von KubiosHRV identifiziert größtenteils die Herzschläge automatisch, trotzdem ist eine manuelle Nachbearbeitung notwendig. Nicht erkannte Herzschläge fügte ich hinzu und zu viel erkannte Herzschläge entfernte ich. \ac{EKG}-Daten mit mehr als 2% an abnormalen Erkennungen habe ich aus der Datensammlung entfernt. 
Zur \ac{HRV}-Analyse nutze ich die letzten fünf Minuten jedes 15-Minuten Abschnittes. Das hatte folgende Gründe:

- Die ersten fünf Minuten sind beeinflusst von der Ruhephase vor dem Lauf und nach jeder Bewertung der \ac{FKS} (siehe Abbildung \ref{fig:ekg-signalverarbeitung} C am Anfang)
- Die letzten fünf Minuten liegen direkt vor der Bewertung der \ac{FKS} (siehe Abbildung \ref{fig:ekg-signalverarbeitung} C am Ende)
- Für die letzten fünf Minuten musste ich keinen Datensatz aufgrund von Artefakten aus der Datensammlung entfernen

```{r ekg-signalverarbeitung, echo=FALSE, warning=FALSE, dev='CairoPNG', dpi=800, fig.height=4.5, fig.width=6.5, fig.pos='htbp', fig.cap='EKG-Signalverarbeitung — (A) Gesamtes EKG-Signal; (B) 15 Minuten EKG-Signal des Laufens; (C) Berechnete RR-Intervalle der 15 Minuten; (D) Abschließenden fünf Minuten RR-Intervalle vor der Bewertung der FKS \\label{fig:ekg-signalverarbeitung}'}
  par(mfcol=c(4, 1), mar=c(3, 3, 1.5, 3) + 0.1, mgp=c(2, .5, 0), las=1, cex.axis=0.8, tck=.01, cex.lab=.8, xaxs="i", yaxs="i")

  # Load ecg data  
  ecg.data.file.path <- paste("./data/example-data/running/buse-patrick/2013-10-31--18-31-19/", sep="")
  ecg.data  <- read.csv(paste(ecg.data.file.path, "ecg-data.csv", sep=""), header=T)

  # Load Kubios HRV txt data
  kubios.hrv.data.path  <- paste("./data/example-data/running/buse-patrick/2013-10-31--18-31-19/", sep="")
  kubios.hrv.data       <- read.csv(paste(kubios.hrv.data.path, "ecg-data-4_hrv.txt", sep = ""), header = F, na.strings = "", fill = T, skip = 117, stringsAsFactors = FALSE, col.names = c("", "Time", "RR.interval", "FFT.Frequency", "FFT.PSD", "AR.Frequency", "AR.PSD", "VLF.comp.", "LF.comp.", "HF.comp.", ""))[,2:3]
  
  # Get time and rr-intervals
  time              <- kubios.hrv.data[, 1]
  time              <- time[complete.cases(time)]
  rr.interval       <- kubios.hrv.data[, 2]
  rr.interval       <- rr.interval[complete.cases(rr.interval)]
  
  # Set time properties
  starts    <- as.POSIXct(fss.features[c(5, 23:26), 7], tz="CET")
  ends      <- as.POSIXct(fss.features[c(5, 23:26), 8], tz="CET")
  times     <- as.POSIXct(ecg.data[, 4]/1000, origin="1970-01-01", tz="CET")
  
  # Set data
  t     <- ecg.data[, 1]
  y     <- ecg.data[, 3]
  end   <- ends[length(ends)]
  start <- starts[length(starts)]
  
  # Plot all ecg data
  plot(t, y, type="l", xlab="", ylab=expression("EKG LA LL ["~mV~"]"), xaxt="n", yaxt="n", col="#1D70B7")
  par(new = T)
  plot(times, y, type="n", xlab="", ylab="", xaxt="n", yaxt="n")

  # Mark interesting part
  polygon(c(start, start, end, end), c(-10, 10, 10, -10), col = rgb(1, 1, 1, .2), border = rgb(0, 0, 0, 0))
  
  # Plot ticks and vertical lines
  axis(1, at=c(starts, ends), label=format(c(starts, ends), "%H:%M:%S"))
  axis(2, at=seq(-6, 6, 2), labels=seq(-6, 6, 2))
  axis(3, labels = NA)
  axis(4, labels = NA)
  abline(v=starts, lty="dashed", col=1)
  abline(v=ends, lty="dashed", col=1)
  
  # Plot box again
  box()
  
  # Add reference letter  
  mtext("A", 4, line=2)

  # Plot the last 15 minutes of ecg data
  isIn         <- start - 30 <= times & end + 30 >= times
  t            <- t[isIn]
  y            <- y[isIn]
  times.subset <- times[isIn]
  
  plot(t, y, type="l", xlab="", ylab=expression("EKG LA LL ["~mV~"]"), xaxt="n", yaxt="n", col="#1D70B7")
  par(new = T)
  plot(times.subset, y, type="n", xlab="", ylab="", xaxt="n", yaxt="n")

  # Plot ticks and vertical lines
  axis(1, at=c(starts, ends), label=format(c(starts, ends), "%H:%M:%S"))
  axis(2, at=seq(-6, 6, 2), labels=seq(-6, 6, 2))
  axis(3, labels = NA)
  axis(4, labels = NA)
  abline(v=starts, lty="dashed", col=1)
  abline(v=ends, lty="dashed", col=1)

  # Plot box again
  box()

  # Add reference letter  
  mtext("B", 4, line=2)

  # Set data
  t         <- time
  y         <- rr.interval
  end.rr    <- max(t)
  start.rr  <- min(t)
  xlim      <- c(start.rr - 30, end.rr + 30)
  
  # Plot rrIntervals
  plot(t, y, type="l", xlab="", ylab=expression("RR-Intervalle ["~s~"]"), xaxt="n", yaxt="n", xlim=xlim, col="#1D70B7")

  # Mark interesting part
  polygon(c(end.rr - 5 * 60, end.rr - 5 * 60, end.rr, end.rr), c(0, 1, 1, -0), col = rgb(1, 1, 1, .2), border = rgb(0, 0, 0, 0))

  # Plot ticks and vertical lines
  marker <- c(start.rr, end.rr - 10 * 60, end.rr - 5 * 60, end.rr)
  axis(1, at=marker, label=format(c(start, end - 10 * 60, end - 5 * 60, end), "%H:%M:%S"))
  axis(2, at=seq(.25, .50, .05), labels=seq(.25, .50, .05))
  axis(3, labels=NA)
  axis(4, labels=NA)
  abline(v=marker, lty = "dashed", col=1)

  # Plot box again
  box()

  # Add reference letter  
  mtext("C", 4, line=2)

  # Set data
  t         <- time[time > max(time) - 5 * 60]
  y         <- rr.interval[time > max(time) - 5 * 60]
  end.rr    <- max(t)
  start.rr  <- min(t)
  xlim      <- c(start.rr - 10, end.rr + 10)
  
  # Plot rrIntervals
  plot(t, y, type="l", xlab="Zeit", ylab=expression("RR-Intervalle ["~s~"]"), xaxt="n", yaxt="n", xlim=xlim, col="#1D70B7")

  # Plot ticks and vertical lines
  marker <- c(start.rr, end.rr)
  axis(1, at=marker, label=format(c(end - 5 * 60, end), "%H:%M:%S"))
  axis(2, at=seq(.2, .6, .02), labels=seq(.2, .6, .02))
  axis(3, at=marker, label=rep("", length(marker)))
  axis(4, at=seq(.2, .6, .02), labels=rep("", length(seq(.2, .6, .02))))
  abline(v=c(min(t), max(t)), lty = "dashed", col=1)

  # Plot box again
  box()

  # Add reference letter  
  mtext("D", 4, line=2)

  # Clean up
  rm(ecg.data.file.path, ecg.data, kubios.hrv.data.path, kubios.hrv.data, ends, end, end.rr, isIn, marker, rr.interval, starts, start, start.rr, t, time, times, times.subset, xlim, y)
```

Nach der Berechnung der RR-Intervalle analysierte ich die \ac{HRV} in R mit Hilfe des Package RHRV \citep{Rodriguez-Linares2010}. Im ersten Schritt filterte ich die RR-Intervalle mit der in RHRV integrierten Filterfunktion. Sie implementiert einen Algorithmus, der einen adaptiven Grenzwert nutzt, um RR-Intervalle abzulehnen oder zu akzeptieren. Der Algorithmus vergleicht den gegenwärtigen RR-Intervall mit dem vorherigen RR-Intervall, dem nachfolgenden RR-Intervall und einem Mittelwert der letzten 50 RR-Intervalle. Der Unterschied zwischen den drei Vergleichen darf für eine Akzeptanz nicht mehr als 13% betragen. Zusätzlich muss der gegenwärtige RR-Intervall zwischen einem Maximalwert und einem Minimalwert von drei Standabweichungen vom Mittelwert liegen, damit die Funktion ihn nicht herausgefiltert (wie bei \citet{DeManzano2010}). Im nächsten Schritt interpolierte ich linear (4 Hz) die RR-Intervalle, damit ein gleicher zeitlicher Abstand zwischen den Datensätzen gewährleistet ist. 

Ein Grundproblem der \ac{HRV}-Analyse unter körperlicher bzw. sportlicher Belastung ist die Nichtstationarität der Zeitreihe der aufeinanderfolgenden RR-Intervalle. Aus diesem Grund empfehlen \citet[S. 113]{Sarmiento2013} traditionelle Methoden der Spektralanalyse wie die \ac{FFT} nicht zu verwenden. Auch \citet[S. 61]{Hoos2010} schreibt von Autoren, die argumentieren, dass für hohe Intensitäten Ergebnisse der traditionellen Spektralanalyse der \ac{HRV} im Allgemeinen und insbesondere der absoluten Einheiten zur Beschreibung der autonomen Funktion unter körperlicher bzw. sportlicher Belastung kaum geeignet sind. Sie führen dies einerseits auf methodische Probleme wie der belastungsbedingten Nichtstationarität und andererseits auf ihre mangelnde Vergleichbarkeit mit Ergebnissen unter schwachen Intensitäten zurück. Vgl. \citet[S. 61]{Hoos2010} lässt sich die gewohnte belastungsinduzierte Verschiebung von der vagalen zur sympathikotonen Dominanz oftmals nicht feststellen. 

Daraus folgt laut \citet[S. 61f.]{Hoos2010} die Forderung deutlich adäquaterer Methoden einzusetzen. Zu diesen Methoden gehören alternative Spektralanalysemethoden (z. B. Coarse Graining Spektralanalyse (CGSA), Kurzzeitfourier-Analyse (STFT) oder kontinuierliche Wavelet Transformation (CWT)) oder nicht-linearer Verfahren (insbesondere Detrended Fluctuation Analysis (DFA), Sampie Entropie (SampEn)). Bei der Nutzung von alternativen Spektralanalysemethoden unter körperlicher bzw. sportlicher Belastung fordern die von \citet[S. 62]{Hoos2010} zitierten Wissenschaftler die Verwendung von einer belastungsadäquaten Erweiterung des HF-Spektralbands mindestens bis zur maximalen Atemfrequenz ($\sim$ 1 Hz). Des Weiteren fordern sie eine Abkehr von der bisherigen Interpretation der Spektralbändern, da sich im \ac{HF}-Band bei körperlicher bzw. sportlicher Belastung vor allem mechanisch bedingte Resonanz- und Kopplungsphänomene mit der Atmung und der motorischen Aktivität zu manifestieren scheinen. 

Aufgrund der vorgestellten Forderungen verwende ich eine \ac{WT} zur Spektralanalyse. Die \ac{WT} ist ein leistungsfähiges Werkzeug zur Analyse von nichtstationären Signalen wie der Zeitreihe der RR-Intervalle. Die Analyse basiert auf einem Mutter-Wavelet. Das Mutter-Wavelet ist eine lokalisierte, oszillierende, reguläre Funktion $\psi(t)$. Wavelet-Funktionen sind anders als die Sinusfunktionen, auf der die \ac{FFT} basiert, im Raum lokalisiert. Dadurch erhält die \ac{WT} die zeitliche und spektrale Dimension. Für die Analyse nichtstationärer Signale ist damit vgl. \citet[S. 207]{Rodriguez-Linares2010} die \ac{WT} der \ac{FFT} vorzuziehen.

Die Verwendung der \ac{WT} ermöglicht die detaillierte Bewertung der Entwicklung der Herzreaktion in der Zeit, in der sich der Organismus auf die Intensität des Laufens, aber vermutlich auch auf die Zustandsveränderung im Flow einrichtet. Die Veränderungen der \ac{HRV}-Signalenergie (Gesamt, \ac{LF} und \ac{HF}-\ac{VHF}) versuche ich als Merkmal für die unterbrechungsfreie Flow-Diagnostik nutzen. Dabei verwende ich die folgenden Signalbänder: \ac{LF} 0.04 - 0.15 Hz; \ac{HF}-\ac{VHF} 0.15 - 1 Hz

Die \ac{WT} führe ich in R mit der Hilfe des RHRV Packages durch. In RHRV implementierten \citet{Rodriguez-Linares2010} eine Maximal Overlap Discrete Wavelet Packet Transform (MODWPT). Zur Analyse stehen mehrere Wavelet-Funktionen mit unterschiedlichen Längen zur Verfügung. Allgemein besitzen kürzere Wavelet-Funktionen eine bessere zeitliche Auflösung, aber eine schlechtere Frequenzauflösung. Auf der anderen Seite, besitzen längere Wellen in der Regel schlechtere zeitliche Auflösung, aber bieten eine bessere Frequenzauflösung. Bessere zeitliche Auflösung ermöglicht es, kürzere Zeitabstände zu studieren. Ich verwende deshalb ein asymmetrische Daubechies Wavelet der Länge 8 (la8), das laut \citet{Rodriguez-Linares2010} einen guten Kompromiss zwischen Frequenz- und Zeitauflösung bietet.

Zur Berechnung der Spektralleistung der unterschiedlichen Bänder in $ms^2$ berechne ich das Mittel der Wavelet Koeffizienten. Die daraus resultierenden \ac{HRV}-Merkmale bildet Tabelle \ref{tab:hrv-merkmale} ab.

```{r hrv-merkmale, echo=FALSE, message=FALSE, warning=FALSE, results="asis"}
    
  # Create table
  options(stringsAsFactors = FALSE)
  feature.table           <- data.frame()
  for (i in 1:9) {
    feature.table <- rbind(feature.table, paste(formatC(round(tapply(hrv.feature.subset[, i], hrv.feature.subset[, 11], mean), 2), format = "f", digits = 2), ",", formatC(round(tapply(hrv.feature.subset[, i], hrv.feature.subset[, 11], sd), 2), format = "f", digits = 2)))
  }
  colnames(feature.table) <- levels(hrv.feature.subset[, 11])
  rownames(feature.table)  <- c("Herzfrequenz (BPM)", "LF ($ms^2$)", "HF-VHF ($ms^2$)", "Gesamt ($ms^2$)", "LF (\\%)", "HF (\\%)", "LF (n. u.)", "HF-VHF (n. u.)", "LF/HF-VHF")
  
  # Print latex table
  table                   <- xtable(feature.table, label = "tab:hrv-merkmale", align = "rzyyyy", caption = "Werte sind arithmetische Mittel ± Standardabweichung; Parameter nach Ruhe, 15-, 30-, 45- und 60-Minuten Laufen [N = 6]") 
  print(table, caption.placement = "top", sanitize.rownames.function = function(x){x}, comment = FALSE, booktabs = TRUE)
  
  # Clean up
  rm(feature.table, table, i)
```

## Statistische Analyse

### Varianzanalyse
Die statistische Analyse der einzelnen Merkmale führte ich mit R durch. Der Effekt des Zeitpunkts der Messung von Ruhe bis zur Minute 60 des Laufens evaluierte ich mit einer einfachen ANOVA bei wiederholten Messungen (ggf. mit Greenhouse-Geisser oder Huynh-Feldt Korrektur). Die Normalverteilung der Daten jeder Stichprobe prüfte ich zahlenmäßig mit dem Shapiro Test und visuell in QQ-Plots. Das Merkmal Besorgnis entfernte ich aus der Datensammlung, da der Läufer sie niedrig und mit geringer Abweichung bewertete. Einen abhängigen t-Test (Paardifferenzentest; engl. Paired t-Test) führte ich falls nötig durch, um die mittlere Differenz zweier Messabschnitte zu berechnen. P-Werte unter 0.05 sah ich als statistisch signifikant an.

```{r examine-features, echo=FALSE, message=FALSE, warning=FALSE, eval=FALSE}

  # Examine fss features (visual)
  par(mfrow = c(1,2), xaxs="r", yaxs="r")
  for(i in 1:5) {
    plot(fss.feature.subset[,i], pch=20 + as.numeric(hrv.feature.subset$measurement), ylab = names(fss.feature.subset)[i])
    boxplot(fss.feature.subset[,i] ~ measurement, data=fss.feature.subset)
  }

  par(mfrow = c(1,1), xaxs="r", yaxs="r")
  for(i in 1:5) {
    hist(fss.feature.subset[,i], main = names(fss.feature.subset)[i], xlab = names(fss.feature.subset)[i])
    lines(density(fss.feature.subset[,i]))
    rug(jitter(fss.feature.subset[,i]))
  } 

  # Examine hrv features (visual)
  par(mfrow = c(1,2), xaxs="r", yaxs="r")
  for(i in 1:9) {
    plot(hrv.feature.subset[,i], pch=20 + as.numeric(hrv.feature.subset$measurement), ylab = names(hrv.feature.subset)[i])
    boxplot(hrv.feature.subset[,i] ~ measurement, data=hrv.feature.subset)
  }
  
  par(mfrow = c(1,1), xaxs="r", yaxs="r")
  for(i in 1:9) {
    hist(hrv.feature.subset[,i], main = names(hrv.feature.subset)[i], xlab = names(hrv.feature.subset)[i])
    lines(density(hrv.feature.subset[,i]))
    rug(jitter(hrv.feature.subset[,i]))
  } 

  rm(i)
```
  
```{r check-group-normality, echo=FALSE, message=FALSE, warning=FALSE, eval=FALSE}

  # Check: Underlying Assumptions: Normality
  
  par(mfrow = c(2,1), xaxs="r", yaxs="r")
  for(i in 1:5) {
    for(j in levels(fss.feature.subset$measurement)) {    
      print(paste(names(fss.feature.subset[fss.feature.subset$measurement == j,])[i], fss.feature.subset[fss.feature.subset$measurement == j,]$measurement[1]))
      print(shapiro.test(fss.feature.subset[fss.feature.subset$measurement == j, i]))
      qqnorm(fss.feature.subset[fss.feature.subset$measurement == j, i], ylab = paste(names(fss.feature.subset[fss.feature.subset$measurement == j,])[i], fss.feature.subset[fss.feature.subset$measurement == j,]$measurement[1]))
      qqline(fss.feature.subset[fss.feature.subset$measurement == j, i])
      plot(fss.feature.subset[fss.feature.subset$measurement == j, i], ylab = paste(names(fss.feature.subset[fss.feature.subset$measurement == j,])[i], fss.feature.subset[fss.feature.subset$measurement == j,]$measurement[1]))
    }
  }
  
  par(mfrow = c(2,1), xaxs="r", yaxs="r")
  for(i in 1:9) {
    for(j in levels(hrv.feature.subset$measurement)) {    
      print(paste(names(hrv.feature.subset[hrv.feature.subset$measurement == j,])[i], hrv.feature.subset[hrv.feature.subset$measurement == j,]$measurement[1]))
      print(shapiro.test(hrv.feature.subset[hrv.feature.subset$measurement == j, i]))
      qqnorm(hrv.feature.subset[hrv.feature.subset$measurement == j, i], ylab = paste(names(hrv.feature.subset[hrv.feature.subset$measurement == j,])[i], hrv.feature.subset[hrv.feature.subset$measurement == j,]$measurement[1]))
      qqline(hrv.feature.subset[hrv.feature.subset$measurement == j, i])
      plot(hrv.feature.subset[hrv.feature.subset$measurement == j, i], ylab = paste(names(hrv.feature.subset[hrv.feature.subset$measurement == j,])[i], hrv.feature.subset[hrv.feature.subset$measurement == j,]$measurement[1]))
    }
  }
  
  rm(i, j)
```

```{r repeated-anova, echo=FALSE, message=FALSE, warning=FALSE, eval=FALSE}
  calculateRepeatedAnova <- function(subject, treatment, value) {
    df            <- data.frame(subject, treatment, value)
    df$subject    <- as.factor(df$subject)
    df$treatment  <- as.factor(df$treatment)
    
    with(df, tapply(value, treatment, mean))
    
  #   aov.out       <- aov(value ~ treatment + Error(subject/treatment), data=df)
  #   print(summary(aov.out))
    
    library(car)
    matrix        <- c()
    treatments    <- levels(df$treatment)
    for(i in 1:length(treatments)) {
      matrix <- cbind(matrix, value[treatment==treatments[i]])
    }
    model         <- lm(matrix ~ 1)
    design        <- factor(treatments)
    options(contrasts=c("contr.sum", "contr.poly"))
    aov.out.3     <- Anova(model, idata = data.frame(design), idesign = ~design, type = "III")
    print(summary(aov.out.3, multivariate = F))
    
    print(with(df, pairwise.t.test(value, treatment, p.adjust.method = "none", paired = T)))
  }
  
  subject <- c()
  for(i in 1:6) {
      subject       <- c(subject, rep(i, length(levels(hrv.feature.subset$measurement))))
  }
  
  for(i in 1:(ncol(fss.feature.subset) - 2)) {
    print(colnames(fss.feature.subset)[i])
    calculateRepeatedAnova(subject, fss.feature.subset$measurement, fss.feature.subset[,i]) 
  }
  
  for(i in 1:(ncol(hrv.feature.subset) - 2)) {
    print(colnames(hrv.feature.subset)[i])
    calculateRepeatedAnova(subject, hrv.feature.subset$measurement, hrv.feature.subset[,i]) 
  }
  
  rm(i, subject)
```

### Korrelationsanalyse
Um mögliche Zusammenhänge zwischen den Faktoren der \ac{FKS} und der Merkmale der \ac{HRV} beim Laufen aufzuklären, berechnete ich den bivariaten Korrelationskoeffizient nach Pearson für alle Kombination von \ac{FKS}-Faktoren und \ac{HRV}-Merkmalen. Die Normalverteilung verifizierte ich mit dem Shapiro Test und QQ-Plots. Gleichzeitig prüfte ich die Beziehung zweier Werte im Streudiagramm. Da dieses Vorgehen nur auf lineare Zusammenhänge testet, berechnete ich zusätzlich wie \citet{Peifer2014} einen möglichen quadratischen Zusammenhang. Für alle Regressionskoeffizienten testete ich mit R die statistische Signifikanz. P-Werte unter 0.05 sah ich als statistisch signifikant an.  

```{r correlation-analysis, echo=FALSE, message=FALSE, warning=FALSE, eval=FALSE}

  lmp <- function (modelobject) {
    if (class(modelobject) != "lm") stop("Not an object of class 'lm' ")
    f <- summary(modelobject)$fstatistic
    p <- pf(f[1],f[2],f[3],lower.tail=F)
    attributes(p) <- NULL
    return(p)
  }

  fss.feature.subset.running <- fss.feature.subset[fss.feature.subset$measurement != "Ruhe", ]
  hrv.feature.subset.running <- hrv.feature.subset[hrv.feature.subset$measurement != "Ruhe", ]

  for(i in c(1:5)) { 
    
    fss.feature      <- fss.feature.subset.running[, i]
    fss.feature.name <- names(fss.feature.subset.running)[i]
    
    par(mfrow = c(2,2), xaxs="r", yaxs="r")
    plot(fss.feature, ylab = fss.feature.name)
    qqnorm(fss.feature, ylab = fss.feature.name)
    qqline(fss.feature)
    boxplot(fss.feature)
    hist(fss.feature, main = fss.feature.name, xlab = fss.feature.name)
    lines(density(fss.feature))
    rug(jitter(fss.feature))
    
    print(fss.feature.name)
    shapiro.test.result.fss.feature <- shapiro.test(fss.feature)
    if(shapiro.test.result.fss.feature$p.value <= .1) {
      print(shapiro.test.result.fss.feature)
    }
  }

  for (j in 1:9) {
      
    hrv.feature      <- hrv.feature.subset.running[, j]
    hrv.feature.name <- names(hrv.feature.subset.running)[j]
    
    if(j == 2 | j == 3 |j == 9) {
        hrv.feature <- sqrt(hrv.feature)
        hrv.feature.name <- paste(hrv.feature.name, "^-.5", sep = "")
      }
      
    par(mfrow = c(2,2), xaxs="r", yaxs="r")
    plot(hrv.feature, ylab = hrv.feature.name)
    qqnorm(hrv.feature, ylab = hrv.feature.name)
    qqline(hrv.feature)
    boxplot(hrv.feature)
    hist(hrv.feature, main = hrv.feature.name, xlab = hrv.feature.name)
    lines(density(hrv.feature))
    rug(jitter(hrv.feature))
      
    print(hrv.feature.name)
    shapiro.test.result.hrv.feature <- shapiro.test(hrv.feature)
    if(shapiro.test.result.hrv.feature$p.value <= .1) {
      print(shapiro.test.result.hrv.feature)
    }
  }
    
  for(i in c(1:3, 5)) {
    
    fss.feature      <- fss.feature.subset.running[, i]
    fss.feature.name <- names(fss.feature.subset.running)[i]
    
    for (j in 1:9) {
      
      hrv.feature      <- hrv.feature.subset.running[, j]
      hrv.feature.name <- names(hrv.feature.subset.running)[j]
      
      if(j == 2 | j == 3 |j == 9) {
        hrv.feature <- sqrt(hrv.feature)
        hrv.feature.name <- paste(hrv.feature.name, "^-.5", sep = "")
      }
      
      print(paste(fss.feature.name, "~", hrv.feature.name))
      
      # linear regression
      linear.model <- lm(fss.feature ~ hrv.feature)
      
      # regression with a quadratic model
      hrv.feature.squared <- hrv.feature^2
      quadratic.model     <- lm(fss.feature ~ hrv.feature + hrv.feature.squared)
    
      linear.model.p.value    <- lmp(linear.model)
      quadratic.model.p.value <- lmp(quadratic.model)
      
      plot.linear.model       <- linear.model.p.value < .1
      plot.quadratic.model    <- quadratic.model.p.value < .1
          
      if(plot.linear.model | plot.quadratic.model) {
        par(mfrow = c(1,1), xaxs="r", yaxs="r")
        plot(hrv.feature, fss.feature, xlab = hrv.feature.name, ylab = fss.feature.name, pch = 21)
      }
        
      if(plot.linear.model) {
        abline(linear.model)
        print(summary(linear.model))
      }
        
      if(plot.quadratic.model) { 
        values           <- seq(min(hrv.feature), max(hrv.feature), .01)
        predicted.values <- predict(quadratic.model, list(hrv.feature = values, hrv.feature.squared = values^2))
        lines(values, predicted.values, lty = 2)
        print(summary(quadratic.model))
      } 
    }
  }

  # Clean up
  rm(fss.feature, fss.feature.name, hrv.feature, hrv.feature.name, hrv.feature.squared, i, j, linear.model, linear.model.p.value, quadratic.model, quadratic.model.p.value, plot.linear.model, plot.quadratic.model, shapiro.test.result.fss.feature, shapiro.test.result.hrv.feature, predicted.values, values)
```

# Ergebnis

## Effekt der Aktivität Laufen auf die Merkmale
Der Generalfaktor unterscheidet sich nur bei der Messung nach der 30. Minute signifikant von der Ruhemessung zu Laufmessung [$t(5) = -2.6458, p < .05$]. In den letzten drei Messungen unterscheiden sich die mittleren Differenzen des angegebenen Verlaufs signifikant. Der glatte Verlauf sinkt von Ruhemessung zum Laufen. Der Effekt auf die Absorbiertheit und die \ac{AFP} ist im Vergleich von Ruhemessung zu den vier Laufmessungen in jedem der vier Stichprobenvergleiche signifikant. Beide Merkmale steigen beim Laufen an. Für alle \ac{HRV}-Merkmale, außer der Gesamtleistung [jeweils $p < .1$] und dem relativen Wert der \ac{LF} [nach der 45. Minute und nach der 60. Minute, $p < .1$], ist der Effekt für jeden Stichprobenvergleich signifikant. Es steigen die mittlere Herzfrequenz, der relative (%) und normalisierte Wert (n. u.) der \ac{HF}. Die restlichen Merkmale fallen von Ruhemessung zum Laufen. Dieses Ergebnis bestätigt bestehende Arbeiten über die \ac{HRV} bei körperlicher bzw. sportlicher Belastung \citep{Pichon2004, Sarmiento2013}. 

## Effekt der Messzeitpunkts auf die Merkmale
Für alle Merkmale, außer der \ac{AFP} und der mittleren Herzfrequenz, ist kein signifikanter Effekt zwischen den einzelnen Laufmessungen zu finden. Damit scheint der Messzeitpunkt auf diese Merkmale keinen Einfluss zu haben. Die gefühlte \ac{AFP} steigt signifikant von Messung der 15. Minute zur Messung der 30. Minute [$t(5) = -7, p < .001$] und von Messung der 30. Minute zur Messung der 45. Minute [$t(5) = -3.16, p < .05$] (siehe Abbildung \ref{fig:zeit-effekt-auf-afp}). Die mittlere Herzfrequenz nach der 15. Minuten unterscheidet sich jeweils von der Messung nach der 30., 45. und 60. Minute [jeweils $p < .1$].

```{r zeit-effekt-auf-afp, echo=FALSE, warning=FALSE, dev='pdf', fig.height=3, fig.width=6.5, fig.pos='htbp', fig.cap='Effekt des Messzeitpunkts auf die AFP \\label{fig:zeit-effekt-auf-afp}'}
  par(mfcol=c(1, 1), mar=c(3.5, 3.5, 1.5, 3.5) + 0.1, mgp=c(2, .5, 0), las=1, cex.axis=0.8, tck=.01, cex.lab=.8, xaxs="r", yaxs="r")
  
  treatment   <- fss.feature.subset$measurement
  treatments  <- levels(treatment)
  value       <- fss.feature.subset[,5]
  df          <- c()
  for(i in 1:length(treatments)) 
    {
    df <- cbind(df, value[treatment==treatments[i]])
  }
  df           <- as.data.frame(df)
  colnames(df) <- levels(fss.feature.subset$measurement)
  
  alpha = 0.05
  means   <- sapply(df, mean)
  lowers  <- sapply(df, function(v) t.test(v, conf.level = 1 - alpha)$conf.int[1])
  uppers  <- sapply(df, function(v) t.test(v, conf.level = 1 - alpha)$conf.int[2])

  ymax    <- max(uppers)

  # Bar plot with 95% confidence interval
  bp <- barplot2(means, plot.ci = TRUE, ci.l = lowers, ci.u = uppers, xpd = FALSE, ylim = c(0, 7), axes = F, ylab = "Anforderungs-Fähigkeits-Passung", col = "#1D70B7")

  # Add connection lines
  x.cord <- sapply(bp, function(x) rep(x, 2))
  y.cord <- rbind(c(uppers * 1.01), rep(1.05 * ymax, length(uppers)))
  
  lines(x.cord[, 1], y.cord[, 1])
  lines(x.cord[, 2], c(y.cord[1, 2], y.cord[2, 2] + .5))
  lines(x.cord[, 3], c(y.cord[1, 3], y.cord[2, 3] + 1))
  lines(x.cord[, 4], c(y.cord[1, 4], y.cord[2, 4] + 1.5))
  lines(x.cord[, 5], c(y.cord[1, 5], y.cord[2, 5] + 1.5))
  lines(x.cord[2, ], y.cord[2, ], lty = 1)
  lines(x.cord[2, 2:5], y.cord[2, 2:5] + .5)
  lines(x.cord[2, 3:5], y.cord[2, 3:5] + 1)
  lines(x.cord[2, 4:5], y.cord[2, 4:5] + 1.5)

  axis(2, at = 0:5, labels = 0:5)
  
  # Add significant star
  # Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

  x.cord.star   <- x.cord[1, ] + c(diff(x.cord[1, ]) / 2, 0)
  y.cord.star   <- c(y.cord[2, 1] + .2, y.cord[2, 1] + .7, y.cord[2, 1] + 1.2, 0)

  df            <- data.frame(treatment, value)
  df$treatment  <- as.factor(df$treatment)
  p             <- with(df, pairwise.t.test(value, treatment, p.adjust.method = "none", paired = T))

  for(i in 1:4) {
    for (j in 1:4) {
      p.value <- p$p.value[j,i]
      star = " "
      if(!is.na(p.value)) {
        if (p.value < 0.001) {
          star = "***"
        } else if (p.value < 0.01) {
          star = "**"
        } else if (p.value < 0.05) {
          star = "*"
        } else if (p.value < 0.1) {
          star = "."
        } else {
          star = " "
        }
      }
      text(star, x = x.cord.star[j], y = y.cord.star[i])
    }
  }
  
  # Clean up
  rm(i, j, df, bp, x.cord, y.cord, alpha, lowers, means, p, p.value, star, treatment, treatments, uppers, value, x.cord.star, y.cord.star, ymax)
```

## Zusammenhänge von Flow-Erleben und HRV
Der Shapiro Test ergab für das Merkmal Besorgnis, für die absoluten Werte der \ac{LF} und \ac{HF} und deren Verhältnis (LH/HF) keine Normalverteilung. Das Merkmal Besorgnis entfernte ich wie bei der Varianzanalyse aus der Datensammlung. Um die Effizienz der Kleinste-Quadrate-Schätzer im linearen Regressionsmodell für die absoluten Werte der \ac{LF} und \ac{HF} und deren Verhältnis zu erhalten, zog ich die Wurzel der Werte. 

<!--
flow    lf.power-a^-0.5  r2 .21  p .083 . inverted-u
flow    hf.power.r       r2 .14  p .075 . \
flow    lf.power.nu      r2 .14  p .073 . /
flow    hf.power.nu      r2 .14  p .073 . \
flow    lfhf^-0.5        r2 .14  p .077 . /
fluency hf.power.r       r2 .19  p .032 * \
fluency lf.power.nu      r2 .18  p .046 * /
fluency hf.power.nu      r2 .18  p .046 * \
fluency lfhf^-0.5        r2 .18  p .040 * /
fit     mean.hr          r2 .45  p .0003 *** /
fit     mean.hr          r2 .46  p .0015 ** inverted-u
-->

Mit jeweils 14% Varianzaufklärung beobachte ich eine schlechte Vorhersagbarkeit des Generalfaktors durch die \ac{HRV}-Merkmale \ac{HF} (%), \ac{LF} (n.u.), \ac{HF} (n.u.) oder LF/HF. Ihre linearen Zusammenhänge liegen jeweils bei einem Signifikanzniveau von $p < 0.1$. Alle weiteren Zusammenhänge liegen bei einem Signifikanzniveau von weit über $p < 0.1$. Die linearen Zusammenhänge zwischen dem glatten Verlauf und den vier genannten \ac{HRV}-Merkmalen verhalten sich ähnlich der Zusammenhänge mit dem Gesamtfaktor. Ihre Varianzaufklärung liegt jeweils bei 18% und mit einem Signifikanzniveau von unter $p < 0.05$ sind diese Zusammenhänge nicht mehr als zufällig zu betrachten. Einen nicht zufälliger systematischen Zusammenhang von Absorbiertheit und einem der \ac{HRV}-Merkmale, wie \citet{Peifer2014} fanden, konnte ich nicht feststellen. Dafür fand ich auch einen quadratischen Zusammenhang mit den absoluten Werten der \ac{LF} (siehe Abbildung \ref{fig:zusammenhaenge-von-flow-und-hrv} A). 

```{r zusammenhaenge-von-flow-und-hrv, echo=FALSE, warning=FALSE, dev='pdf', fig.height=3, fig.width=6.5, fig.pos='htbp', fig.cap='Systematische lineare Zusammenhänge von (A) Flow und dem Verhältnis von LF und HF [R2 = .18, F(1, 21) = 4.5, p < .05]; (B) der AFP und der mittleren Herzfrequenz [R2 = .48, F(1, 21) = 19.25, p < .001] \\label{fig:zusammenhaenge-von-flow-und-hrv}'}
  par(mfcol=c(1, 3), mar=c(3.5, 3.5, 1.5, 3.5) + 0.1, mgp=c(2, .5, 0), las=1, cex.axis=0.8, tck=.01, cex.lab=.8, xaxs="r", yaxs="r")

  fss.feature.subset.running <- fss.feature.subset[fss.feature.subset$measurement != "Ruhe", ] 
  fss.feature.subset.running <- fss.feature.subset.running[c(1:10, 12:24),]

  hrv.feature.subset.running <- hrv.feature.subset[hrv.feature.subset$measurement != "Ruhe", ] 
  hrv.feature.subset.running <- hrv.feature.subset.running[c(1:10, 12:24),]
  
  fss.feature         <- fss.feature.subset.running[, 1]
  hrv.feature         <- hrv.feature.subset.running[, 2]
  hrv.feature.squared <- hrv.feature^2

  # Plot data
  plot(hrv.feature, fss.feature, xlab = expression("LF [" ~ ms^2 ~ "]"), ylab = "Flow", pch = 21, bg = "#1D70B7", ylim = c(3, 6))

  quadratic.model  <- lm(fss.feature ~ hrv.feature + hrv.feature.squared)
  values           <- seq(min(hrv.feature) - 1, max(hrv.feature) + 1, .01)
  predicted.values <- predict(quadratic.model, list(hrv.feature = values, hrv.feature.squared = values^2))
  lines(values, predicted.values, lty = 2)

  # Plot tick
  axis(3, label = NA)
  axis(4, label = NA)

  # Plot box again
  box()

  # Add reference letter  
  mtext("A", 3, line=.2)

  fss.feature         <- fss.feature.subset.running[, 1]
  hrv.feature         <- hrv.feature.subset.running[, 2]
  hrv.feature.squared <- hrv.feature^2

  # Plot data
  plot(hrv.feature, fss.feature, xlab = expression("LF [" ~ ms^2 ~ "]"), ylab = "Flow", pch = 21, bg = "#1D70B7", ylim = c(3, 6))

  quadratic.model  <- lm(fss.feature ~ hrv.feature + hrv.feature.squared)
  values           <- seq(min(hrv.feature) - 1, max(hrv.feature) + 1, .01)
  predicted.values <- predict(quadratic.model, list(hrv.feature = values, hrv.feature.squared = values^2))
  lines(values, predicted.values, lty = 2)

  # Plot tick
  axis(3, label = NA)
  axis(4, label = NA)

  # Plot box again
  box()

  # Add reference letter  
  mtext("A", 3, line=.2)

  # Plot data
  plot(hrv.feature.subset.running[, 1], fss.feature.subset.running[, 5], xlab = "Mittlere Herzfrequenz [ BPM ]", ylab = "Anforderungs-Fähigkeits-Passung", pch = 21, bg = "#1D70B7", ylim = c(3, 6))
  
  abline(lm(fss.feature.subset.running[, 5] ~ hrv.feature.subset.running[, 1]))

  # Plot tick
  axis(3, label = NA)
  axis(4, label = NA)

  # Plot box again
  box()

  # Add reference letter  
  mtext("B", 3, line=.2)
```

Ein Indiz dafür, dass der Läufer die \ac{FKS} gewissenhaft ausgefüllt hat, zeigt der Zusammenhang zwischen \ac{AFP} und mittlerer Herzfrequenz. Mit 45% Varianzaufklärung beobachte ich eine mittlere Vorhersagbarkeit. Es besteht ein nicht zufälliger systematischer linearer Zusammenhang zwischen der \ac{AFP} und der mittleren Herzfrequenz [$p < 0.001$]. Aber ich stelle auch einen nicht zufälligen systematischen quadrischen Zusammenhang zwischen \ac{AFP} und mittlerer Herzfrequenz [$p < 0.01$]. Durch ein quadratisches Modell erhöht sich die Varianzaufklärung auf 46% (siehe Abbildung \ref{fig:zusammenhaenge-von-flow-und-hrv} B).

## Interpretation

Im Gegensatz zu den Ergebnissen in \citet{Peifer2014} verhält sich der Zusammenhang zwischen Flow (bestimmt durch den Generalfaktor) und der \ac{HF} beim Laufen genau anders herum (siehe Abbildung \ref{fig:zusammenhaenge-von-flow-und-hrv} B). Der Grund dafür ist die körperliche bzw. sportliche Belastung und die dadurch notwendige Anpassung der Frequenzbänder. Durch die Anpassung ist die übliche rein neuro-vegetative, sympathiko-vagale Interpretation der Spektralbänder nicht möglich, da sich im \ac{HF}-Band bei körperlicher bzw. sportlicher Belastung vor allem mechanisch bedingte Resonanz- und Kopplungsphänomene mit der Atmung und der motorischen Aktivität zu manifestieren scheinen \citep[S. 62]{Hoos2010}. Eine Zugehörigkeitsbestimmung der \ac{HF} zur vagalen Aktivität des \ac{ANS}s, wie bei der rein neuro-vegetativen, sympathiko-vagalen Interpretation, wäre deshalb fehlerhaft. Was \ac{HF} außerhalb der üblichen euro-vegetativen, sympathiko-vagalen Interpretation der Spektralbänder über die Prozesse in unserem Körper sagen, kann ich zum jetzigen Zeitpunkt nicht sagen. Deswegen bietet sich für mich, die weitere Nutzung des \ac{HRV}-Merkmals \ac{HF} nur in individuellen Schwellenkonzepten an. In einem weiteren Ansatz könnte ich den direkten Zusammenhang zwischen der zeitvarianten spektralen Kenngröße der \ac{HF} mit ventilatorischen Schwellenkonzepten nach \citet{Cottin2007} untersuchen. Der Ansatz könnte mit Hilfe der Herzfrequenzmessung einen Zusammenhang der Atemfrequenz und Flow ermöglichen. 
Der Zusammenhang zwischen Flow und den absoluten Werten der \ac{LF} verhält sich wie bei \citet{Peifer2014} und stellt sich als umgedrehtes U dar. Dies spricht dafür, dass eine moderate Beanspruchung durch die Tätigkeit für Flow gegeben sein muss. Für diese Annahme spricht auch der nicht zufälliger systematischer quadrischer Zusammenhang von \ac{AFP} und mittlerer Herzfrequenz. Steigt die Herzfrequenz über einen individuellen Maximalwert hinweg, fällt die \ac{AFP}. Leider konnte ich keinen Zusammenhang zwischen Generalfaktor und \ac{AFP} oder mittlerer Herzfrequenz herstellen.

## Jerk Cost

\begin{equation}
  JC = \int_0^T dt ((\frac{d^3x}{dt^3})^2 + (\frac{d^3y}{dt^3})^2 + (\frac{d^3z}{dt^3})^2 ) 
\end{equation}

\bibliographystyle{agsm}
\bibliography{./bibtex/library}